<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"llunch4w.github.io","root":"/","scheme":"Pisces","version":"8.0.0-rc.3","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="^ _ ^">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习模型编写范式">
<meta property="og:url" content="https://llunch4w.github.io/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/index.html">
<meta property="og:site_name" content="摸鱼的Llunch">
<meta property="og:description" content="^ _ ^">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://llunch4w.github.io/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/1.png">
<meta property="article:published_time" content="2022-04-25T07:56:32.000Z">
<meta property="article:modified_time" content="2022-04-28T12:46:43.465Z">
<meta property="article:author" content="Llunch">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://llunch4w.github.io/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/1.png">

<link rel="canonical" href="https://llunch4w.github.io/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>深度学习模型编写范式 | 摸鱼的Llunch</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before, .use-motion .logo-line-after {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line toggle-line-first"></span>
        <span class="toggle-line toggle-line-middle"></span>
        <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line-before"></i>
      <h1 class="site-title">摸鱼的Llunch</h1>
      <i class="logo-line-after"></i>
    </a>
      <p class="site-subtitle" itemprop="description">但行好事，莫问前程</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Step1-读取配置"><span class="nav-number">1.</span> <span class="nav-text">Step1: 读取配置</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step2-构建一个日志记录器"><span class="nav-number">2.</span> <span class="nav-text">Step2: 构建一个日志记录器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step3-GPU设置"><span class="nav-number">3.</span> <span class="nav-text">Step3: GPU设置</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础"><span class="nav-number">3.1.</span> <span class="nav-text">基础</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#拓展-–-分布式GPU"><span class="nav-number">3.2.</span> <span class="nav-text">拓展 – 分布式GPU</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step4-数据准备"><span class="nav-number">4.</span> <span class="nav-text">Step4: 数据准备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#processor类调用方式"><span class="nav-number">4.1.</span> <span class="nav-text">processor类调用方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#processor类的编写"><span class="nav-number">4.2.</span> <span class="nav-text">processor类的编写</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基类编写"><span class="nav-number">4.2.1.</span> <span class="nav-text">基类编写</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#以Cner数据集为例"><span class="nav-number">4.2.2.</span> <span class="nav-text">以Cner数据集为例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step5-加载预训练模型"><span class="nav-number">5.</span> <span class="nav-text">Step5: 加载预训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#加载方式"><span class="nav-number">5.1.</span> <span class="nav-text">加载方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络结构编写"><span class="nav-number">5.2.</span> <span class="nav-text">网络结构编写</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Classifier"><span class="nav-number">5.2.1.</span> <span class="nav-text">Classifier</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF"><span class="nav-number">5.2.2.</span> <span class="nav-text">CRF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#指定模型训练GPU"><span class="nav-number">5.3.</span> <span class="nav-text">指定模型训练GPU</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step6-加载数据"><span class="nav-number">6.</span> <span class="nav-text">Step6: 加载数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step7-模型训练"><span class="nav-number">7.</span> <span class="nav-text">Step7: 模型训练</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#train函数编写"><span class="nav-number">7.1.</span> <span class="nav-text">train函数编写</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#data-loader"><span class="nav-number">7.1.1.</span> <span class="nav-text">data_loader</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prepare-optimizer-and-schedule"><span class="nav-number">7.1.2.</span> <span class="nav-text">Prepare optimizer and schedule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-number">7.1.3.</span> <span class="nav-text">训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step8-保存最好的模型结果"><span class="nav-number">7.2.</span> <span class="nav-text">Step8: 保存最好的模型结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step9-在dev集上评估"><span class="nav-number">7.3.</span> <span class="nav-text">Step9: 在dev集上评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Step9-在test集上预测"><span class="nav-number">7.4.</span> <span class="nav-text">Step9: 在test集上预测</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Llunch"
      src="/images/me.jpg">
  <p class="site-author-name" itemprop="name">Llunch</p>
  <div class="site-description" itemprop="description">Laugh through the night</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">119</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">79</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Llunch4w" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Llunch4w" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://llunch4w.github.io/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me.jpg">
      <meta itemprop="name" content="Llunch">
      <meta itemprop="description" content="Laugh through the night">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="摸鱼的Llunch">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习模型编写范式
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-25 15:56:32" itemprop="dateCreated datePublished" datetime="2022-04-25T15:56:32+08:00">2022-04-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-28 20:46:43" itemprop="dateModified" datetime="2022-04-28T20:46:43+08:00">2022-04-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote class="blockquote-center">
<p>^ _ ^ </p>

</blockquote>
<a id="more"></a>

<p>本文基于代码基于pytorch库.</p>
<h1 id="Step1-读取配置"><a href="#Step1-读取配置" class="headerlink" title="Step1: 读取配置"></a>Step1: 读取配置</h1><p><strong>template</strong>    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"-t"</span>, <span class="string">"--task_name"</span>, default=<span class="literal">None</span>, type=str, required=<span class="literal">True</span>,</span><br><span class="line">                        help=<span class="string">"The name of the task to train selected in the list: "</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--markup'</span>, default=<span class="string">'bios'</span>, type=str, choices=[<span class="string">'bios'</span>, <span class="string">'bio'</span>])</span><br><span class="line">parser.add_argument(<span class="string">"--do_train"</span>, action=<span class="string">"store_true"</span>, help=<span class="string">"Whether to run training."</span>)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>以上参数均可通过shell脚本进行传入</p>
</blockquote>
<h1 id="Step2-构建一个日志记录器"><a href="#Step2-构建一个日志记录器" class="headerlink" title="Step2: 构建一个日志记录器"></a>Step2: 构建一个日志记录器</h1><blockquote>
<p>日志记录器最好可以同时写控制台和文件</p>
</blockquote>
<p><strong>definition template</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># common.py</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># global variable</span></span><br><span class="line">logger = logging.getLogger()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_logger</span><span class="params">(log_file=None, log_file_level=logging.NOTSET)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; init_logger(log_file)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; logger.info("abc'")</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(log_file,Path):</span><br><span class="line">        log_file = str(log_file)</span><br><span class="line">    log_format = logging.Formatter(fmt=<span class="string">'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'</span>,</span><br><span class="line">                                   datefmt=<span class="string">'%m/%d/%Y %H:%M:%S'</span>)</span><br><span class="line"></span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">    logger.setLevel(logging.INFO)</span><br><span class="line">    console_handler = logging.StreamHandler()</span><br><span class="line">    console_handler.setFormatter(log_format)</span><br><span class="line">    logger.handlers = [console_handler]</span><br><span class="line">    <span class="keyword">if</span> log_file <span class="keyword">and</span> log_file != <span class="string">''</span>:</span><br><span class="line">        file_handler = logging.FileHandler(log_file)</span><br><span class="line">        file_handler.setLevel(log_file_level)</span><br><span class="line">        <span class="comment"># file_handler.setFormatter(log_format)</span></span><br><span class="line">        logger.addHandler(file_handler)</span><br><span class="line">    <span class="keyword">return</span> logger</span><br></pre></td></tr></table></figure>

<p><strong>use template</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> common <span class="keyword">import</span> logger</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">time_ = time.strftime(<span class="string">"%Y-%m-%d-%H:%M:%S"</span>, time.localtime())</span><br><span class="line">init_logger(log_file=args.output_dir + <span class="string">f'/<span class="subst">&#123;args.model_type&#125;</span>-<span class="subst">&#123;args.task_name&#125;</span>-<span class="subst">&#123;time_&#125;</span>.log'</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Step3-GPU设置"><a href="#Step3-GPU设置" class="headerlink" title="Step3: GPU设置"></a>Step3: GPU设置</h1><blockquote>
<p>Setup CUDA, GPU &amp; distrubuted training</p>
</blockquote>
<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为保证多次训练结果一致, 需要设置确定的随机数种子</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seed_everything</span><span class="params">(seed=<span class="number">1029</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    设置整个开发环境的seed</span></span><br><span class="line"><span class="string">    :param seed:</span></span><br><span class="line"><span class="string">    :param device:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">'PYTHONHASHSEED'</span>] = str(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    <span class="comment"># some cudnn methods can be random even after fixing the seed</span></span><br><span class="line">    <span class="comment"># unless you tell it to be deterministic</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">seed_everything(args.seed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cpu or gpu</span></span><br><span class="line"><span class="comment"># local_rank 表示用于训练的gpu</span></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">-1</span> <span class="keyword">or</span> args.no_cuda:</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">and</span> <span class="keyword">not</span> args.no_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    torch.cuda.set_device(args.local_rank)</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>, args.local_rank)</span><br></pre></td></tr></table></figure>

<h2 id="拓展-–-分布式GPU"><a href="#拓展-–-分布式GPU" class="headerlink" title="拓展 – 分布式GPU"></a>拓展 – 分布式GPU</h2><p>可以使用 <code>torch.distributed</code> 包进行单机多卡的GPU分布式训练.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 几个常见函数, 具体使用方法没有弄懂, 仅作罗列</span></span><br><span class="line">torch.distributed.init_process_group(backend=<span class="string">"nccl"</span>)</span><br><span class="line">torch.distributed.barrier()</span><br><span class="line">torch.distributed.get_rank()</span><br><span class="line">torch.distributed.get_world_size()</span><br></pre></td></tr></table></figure>

<h1 id="Step4-数据准备"><a href="#Step4-数据准备" class="headerlink" title="Step4: 数据准备"></a>Step4: 数据准备</h1><blockquote>
<p>一般而言, 不同的数据集需要的处理方法是不同的, 因此可以通过实现不同的Processor类来分别完成各个数据集的处理工作.</p>
</blockquote>
<h2 id="processor类调用方式"><a href="#processor类调用方式" class="headerlink" title="processor类调用方式"></a>processor类调用方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># processor.py</span></span><br><span class="line"><span class="comment"># global</span></span><br><span class="line">ner_processors = &#123;</span><br><span class="line">    <span class="string">"cner"</span>: CnerProcessor,</span><br><span class="line">    <span class="string">'cluener'</span>:CluenerProcessor</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># main.py</span></span><br><span class="line"><span class="keyword">from</span> processor <span class="keyword">import</span> ner_processor <span class="keyword">as</span> processors</span><br><span class="line">args.task_name = args.task_name.lower()</span><br><span class="line"><span class="keyword">if</span> args.task_name <span class="keyword">not</span> <span class="keyword">in</span> processors:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Task not found: %s"</span> % (args.task_name))</span><br><span class="line">processor = processors[args.task_name]()</span><br><span class="line">label_list = processor.get_labels()</span><br><span class="line">args.id2label = &#123;i: label <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(label_list)&#125;</span><br><span class="line">args.label2id = &#123;label: i <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(label_list)&#125;</span><br></pre></td></tr></table></figure>

<h2 id="processor类的编写"><a href="#processor类的编写" class="headerlink" title="processor类的编写"></a>processor类的编写</h2><h3 id="基类编写"><a href="#基类编写" class="headerlink" title="基类编写"></a>基类编写</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataProcessor</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Base class for data converters for ner task data sets."""</span></span><br><span class="line">    <span class="comment"># 这里的 InputExample 在不同的数据集上也是不同的</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">        <span class="string">"""Gets a collection of `InputExample`s for the train set."""</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_dev_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">        <span class="string">"""Gets a collection of `InputExample`s for the dev set."""</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Gets the list of labels for this data set."""</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_read_text</span><span class="params">(self,input_file)</span>:</span></span><br><span class="line">        lines = []</span><br><span class="line">        <span class="keyword">with</span> open(input_file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            words = []</span><br><span class="line">            labels = []</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">"-DOCSTART-"</span>) <span class="keyword">or</span> line == <span class="string">""</span> <span class="keyword">or</span> line == <span class="string">"\n"</span>:</span><br><span class="line">                    <span class="keyword">if</span> words:</span><br><span class="line">                        lines.append(&#123;<span class="string">"words"</span>:words,<span class="string">"labels"</span>:labels&#125;)</span><br><span class="line">                        words = []</span><br><span class="line">                        labels = []</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    splits = line.split(<span class="string">" "</span>)</span><br><span class="line">                    words.append(splits[<span class="number">0</span>])</span><br><span class="line">                    <span class="keyword">if</span> len(splits) &gt; <span class="number">1</span>:</span><br><span class="line">                        labels.append(splits[<span class="number">-1</span>].replace(<span class="string">"\n"</span>, <span class="string">""</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># Examples could have no label for mode = "test"</span></span><br><span class="line">                        labels.append(<span class="string">"O"</span>)</span><br><span class="line">            <span class="keyword">if</span> words:</span><br><span class="line">                lines.append(&#123;<span class="string">"words"</span>:words,<span class="string">"labels"</span>:labels&#125;)</span><br><span class="line">        <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_read_json</span><span class="params">(self,input_file)</span>:</span></span><br><span class="line">        lines = []</span><br><span class="line">        <span class="keyword">with</span> open(input_file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                line = json.loads(line.strip())</span><br><span class="line">                text = line[<span class="string">'text'</span>]</span><br><span class="line">                label_entities = line.get(<span class="string">'label'</span>,<span class="literal">None</span>)</span><br><span class="line">                words = list(text)</span><br><span class="line">                labels = [<span class="string">'O'</span>] * len(words)</span><br><span class="line">                <span class="keyword">if</span> label_entities <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">for</span> key,value <span class="keyword">in</span> label_entities.items():</span><br><span class="line">                        <span class="keyword">for</span> sub_name,sub_index <span class="keyword">in</span> value.items():</span><br><span class="line">                            <span class="keyword">for</span> start_index,end_index <span class="keyword">in</span> sub_index:</span><br><span class="line">                                <span class="keyword">assert</span>  <span class="string">''</span>.join(words[start_index:end_index+<span class="number">1</span>]) == sub_name</span><br><span class="line">                                <span class="keyword">if</span> start_index == end_index:</span><br><span class="line">                                    labels[start_index] = <span class="string">'S-'</span>+key</span><br><span class="line">                                <span class="keyword">else</span>:</span><br><span class="line">                                    labels[start_index] = <span class="string">'B-'</span>+key</span><br><span class="line">                                    labels[start_index+<span class="number">1</span>:end_index+<span class="number">1</span>] = [<span class="string">'I-'</span>+key]*(len(sub_name)<span class="number">-1</span>)</span><br><span class="line">                lines.append(&#123;<span class="string">"words"</span>: words, <span class="string">"labels"</span>: labels&#125;)</span><br><span class="line">        <span class="keyword">return</span> lines</span><br></pre></td></tr></table></figure>

<p><code>DataProcessor</code>类中主要针对两种ner输入文件格式进行解析, 返回类型均为 <code>dict_list</code>.<br><strong>txt样板</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">吴 B-NAME</span><br><span class="line">重 I-NAME</span><br><span class="line">阳 E-NAME</span><br><span class="line">， O</span><br><span class="line">中 B-CONT</span><br><span class="line">国 I-CONT</span><br><span class="line">国 I-CONT</span><br><span class="line">籍 E-CONT</span><br><span class="line"></span><br><span class="line">历 O</span><br><span class="line">任 O</span><br><span class="line">公 B-ORG</span><br><span class="line">司 E-ORG</span><br><span class="line">副 B-TITLE</span><br><span class="line">总 M-TITLE</span><br><span class="line">经 M-TITLE</span><br><span class="line">理 E-TITLE</span><br></pre></td></tr></table></figure>

<p><strong>json样板</strong></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"text"</span>: <span class="string">"浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，"</span>, <span class="attr">"label"</span>: &#123;<span class="attr">"name"</span>: &#123;<span class="attr">"叶老桂"</span>: [[<span class="number">9</span>, <span class="number">11</span>]]&#125;, <span class="attr">"company"</span>: &#123;<span class="attr">"浙商银行"</span>: [[<span class="number">0</span>, <span class="number">3</span>]]&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="以Cner数据集为例"><a href="#以Cner数据集为例" class="headerlink" title="以Cner数据集为例"></a>以Cner数据集为例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InputExample</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""A single training/test example for ner task"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, guid, text_a, labels)</span>:</span></span><br><span class="line">        <span class="string">"""Constructs a InputExample.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            guid: Unique id for the example.</span></span><br><span class="line"><span class="string">            text_a: list. The words of the sequence.</span></span><br><span class="line"><span class="string">            labels: (Optional) list. The labels for each word of the sequence. This should be</span></span><br><span class="line"><span class="string">            specified for train and dev examples, but not for test examples.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.guid = guid</span><br><span class="line">        self.text_a = text_a</span><br><span class="line">        self.labels = labels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> str(self.to_json_string())</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_dict</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Serializes this instance to a Python dictionary."""</span></span><br><span class="line">        output = copy.deepcopy(self.__dict__)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_json_string</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Serializes this instance to a JSON string."""</span></span><br><span class="line">        <span class="keyword">return</span> json.dumps(self.to_dict(), indent=<span class="number">2</span>, sort_keys=<span class="literal">True</span>) + <span class="string">"\n"</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnerProcessor</span><span class="params">(DataProcessor)</span>:</span></span><br><span class="line">    <span class="string">"""Processor for the chinese ner data set."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, element_dict_file)</span>:</span></span><br><span class="line">        <span class="string">'''load label dict</span></span><br><span class="line"><span class="string">            element_dict format: &#123;"Name": "姓名", "Age": "年龄"&#125;</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">assert</span> os.path.existed(element_dict_file)</span><br><span class="line">        <span class="keyword">with</span> open(element_dict_file, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.element_dict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_path)</span>:</span></span><br><span class="line">        <span class="string">"""See base class."""</span></span><br><span class="line">        <span class="keyword">assert</span> os.path.existed(data_path)</span><br><span class="line">        <span class="keyword">return</span> self._create_examples(self._read_text(data_path), <span class="string">"train"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_dev_examples</span><span class="params">(self, data_path)</span>:</span></span><br><span class="line">        <span class="string">"""See base class."""</span></span><br><span class="line">        <span class="keyword">assert</span> os.path.existed(data_path)</span><br><span class="line">        <span class="keyword">return</span> self._create_examples(self._read_text(data_path, <span class="string">"dev"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_test_examples</span><span class="params">(self, data_path)</span>:</span></span><br><span class="line">        <span class="string">"""See base class."""</span></span><br><span class="line">        <span class="keyword">assert</span> os.path.existed(data_path)</span><br><span class="line">        <span class="keyword">return</span> self._create_examples(self._read_text(data_path, <span class="string">"test"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""See base class."""</span></span><br><span class="line">        label_list = []</span><br><span class="line">        <span class="keyword">for</span> elem_name <span class="keyword">in</span> self.element_dict.keys():</span><br><span class="line">            label_list.append(<span class="string">f"B-<span class="subst">&#123;elem_name&#125;</span>"</span>)</span><br><span class="line">            label_list.append(<span class="string">f"I-<span class="subst">&#123;elem_name&#125;</span>"</span>)</span><br><span class="line">            label_list.append(<span class="string">f"S-<span class="subst">&#123;elem_name&#125;</span>"</span>)</span><br><span class="line">        label_list.extend([<span class="string">"X"</span>, <span class="string">"O"</span>, <span class="string">"[START]"</span>, <span class="string">"[END]"</span>])</span><br><span class="line">        <span class="keyword">return</span> label_list</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个函数主要是将一些与预训练模型所接受数据格式不同的数据进行转换. 比如将bioes, bios, bmos等各种各样格式转换为统一的bio格式</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_examples</span><span class="params">(self, lines, set_type)</span>:</span></span><br><span class="line">        <span class="string">"""Creates examples for the training and dev sets."""</span></span><br><span class="line">        examples = []</span><br><span class="line">        <span class="keyword">for</span> (i, line) <span class="keyword">in</span> enumerate(lines):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            guid = <span class="string">"%s-%s"</span> % (set_type, i)</span><br><span class="line">            text_a= line[<span class="string">'words'</span>]</span><br><span class="line">            <span class="comment"># BIOS</span></span><br><span class="line">            labels = []</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> line[<span class="string">'labels'</span>]:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">'M-'</span> <span class="keyword">in</span> x:</span><br><span class="line">                    labels.append(x.replace(<span class="string">'M-'</span>,<span class="string">'I-'</span>))</span><br><span class="line">                <span class="keyword">elif</span> <span class="string">'E-'</span> <span class="keyword">in</span> x:</span><br><span class="line">                    labels.append(x.replace(<span class="string">'E-'</span>, <span class="string">'I-'</span>))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    labels.append(x)</span><br><span class="line">            examples.append(InputExample(guid=guid, text_a=text_a, labels=labels))</span><br><span class="line">        <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>

<h1 id="Step5-加载预训练模型"><a href="#Step5-加载预训练模型" class="headerlink" title="Step5: 加载预训练模型"></a>Step5: 加载预训练模型</h1><h2 id="加载方式"><a href="#加载方式" class="headerlink" title="加载方式"></a>加载方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertTokenizer</span><br><span class="line"><span class="keyword">from</span> models.bert_for_ner <span class="keyword">import</span> BertCrfForNer</span><br><span class="line"></span><br><span class="line">MODEL_CLASSES = &#123;</span><br><span class="line">    <span class="comment">## bert ernie bert_wwm bert_wwwm_ext</span></span><br><span class="line">    <span class="string">'bert'</span>: (BertConfig, BertCrfForNer, BertTokenizer),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">args.model_type = args.model_type.lower()</span><br><span class="line">config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]</span><br><span class="line">config = config_class.from_pretrained(args.model_name_or_path,num_labels=num_labels,)</span><br><span class="line">tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path, do_lower_case=args.do_lower_case,)</span><br><span class="line">model = model_class.from_pretrained(args.model_name_or_path, config=config)</span><br></pre></td></tr></table></figure>

<p>预训练模型可以去 <strong>hugging face</strong> 官网上进行下载. 对于基于 pytorch 的预训练模型, 主要下载 <code>config.json</code>(对应<code>BertConfig</code>类的初始化), <code>vocab.txt</code>(对应<code>BertTokenize</code>类的初始化), <code>pytorch.bin</code>(对应预训练模型).</p>
<blockquote>
<p>很多时候, 我们会在预训练模型之后增加一些神经网络层进行微调. 比如这个例子中, <code>BertCrfForNer</code> 就是由程序员编写, 而不是像<code>BertConfig</code>和<code>BertTokenizer</code>一样直接从<code>transformers</code>库中引用.</p>
</blockquote>
<h2 id="网络结构编写"><a href="#网络结构编写" class="headerlink" title="网络结构编写"></a>网络结构编写</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .layers.crf <span class="keyword">import</span> CRF</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel, BertPreTrainedModel</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertCrfForNer</span><span class="params">(BertPreTrainedModel)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, config)</span>:</span></span><br><span class="line">        super(BertCrfForNer, self).__init__(config)</span><br><span class="line">        self.bert = BertModel(config)</span><br><span class="line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</span><br><span class="line">        self.classifier = nn.Linear(config.hidden_size, config.num_labels)</span><br><span class="line">        self.crf = CRF(num_tags=config.num_labels, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.init_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_ids, token_type_ids=None, attention_mask=None,labels=None)</span>:</span></span><br><span class="line">        outputs =self.bert(input_ids = input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)</span><br><span class="line">        sequence_output = outputs[<span class="number">0</span>]</span><br><span class="line">        sequence_output = self.dropout(sequence_output)</span><br><span class="line">        logits = self.classifier(sequence_output)</span><br><span class="line">        outputs = (logits,)</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = self.crf(emissions = logits, tags=labels, mask=attention_mask)</span><br><span class="line">            outputs =(<span class="number">-1</span>*loss,)+outputs</span><br><span class="line">        <span class="keyword">return</span> outputs <span class="comment"># (loss), scores</span></span><br></pre></td></tr></table></figure>

<p>其中, <code>BertPreTrainedModel</code>是一个抽象类, 包含<code>_init_weights</code>来处理参数初始化; <code>BertModel</code> 是一个基础的Bert网络架构, 需要通过 <code>configs</code> 传入一些参数. 不过这些参数不需要程序员设定, 可以直接从<code>BertConfig</code>中进行读取.</p>
<p><img src="/2022/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%BC%96%E5%86%99%E8%8C%83%E5%BC%8F/1.png" alt></p>
<p>整个<code>BertCrfForNer</code>由两部分组成: </p>
<ul>
<li>第一部分相当于一个分类模型. 输入一个词, 输出是这个词被标注为各个label的概率.</li>
<li>第二部分是CRF. 输入一段文本, 这个文本中每个词经过第一部分都会得到一个概率向量. 根据label之间的约束, 找到一条联合概率最大的路径作为输出结果, 即为输入文本对应的标注结果.</li>
</ul>
<h3 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h3><blockquote>
<p>bert –&gt; dropout –&gt; classifier</p>
</blockquote>
<h3 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h3><p><code>CRF</code>可以继承<code>torch.nn.Module</code>类作为<code>Bert</code>层后的连接层. Bert层的输出是一个3维矩阵: $batch_size \times sequence_length \times label_nums$. 对于 sequence 中的每个词, 都会对应所有<code>label</code> 有一个特定的概率. 一种简单的做法是直接取<strong>概率最大</strong>的那个label作为该词的输出label. 但这种简单的方式忽略了 label 之间的依赖和约束关系. 比如 B-Product 标签后面一定不会再跟一个 B-Product. 而 CRF 层同时考虑了label之间的依赖约束关系和Bert层的到的概率矩阵. </p>
<p>CRF层中比较重要的几个变量是:</p>
<ul>
<li>start_transitions, end_transitions: 一维向量, 长度为 label_num , 分别表示每个 label 出现在句首和句尾的概率.</li>
<li>transitions: 转移矩阵, shape 为 $label_num \times label_num$, mat[i, j]表示 label_i  后面跟 label_j 的概率.</li>
<li>emissions: 发射矩阵, shape 为 $batch_size \times sequence_length \times label_nums$, 即 Bert 层输出结果.</li>
</ul>
<p>以上三个矩阵都不需要人为设置, 其中<code>start_transitions, end_transitions, transitions</code>三个参数CRF层会在模型训练的过层中自动调整, 而<code>emissions</code>是Bert层传入的参数, 会在Bert层进行自动调整. 因此在<code>CRF</code>类中也需要定义<code>forward</code>函数, 传入主要参数包括 <code>emissions</code>(Bert层输出结果), <code>tags</code>(正确label序列), <code>mask</code>(元素类型为bool的大小为$label_num \time label_num$的矩阵, mat[i, j]表示label_i的下一个label是否可以为label_j).</p>
<h2 id="指定模型训练GPU"><a href="#指定模型训练GPU" class="headerlink" title="指定模型训练GPU"></a>指定模型训练GPU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.to(args.device)</span><br><span class="line">logger.info(<span class="string">"Training/evaluation parameters %s"</span>, args)</span><br></pre></td></tr></table></figure>

<h1 id="Step6-加载数据"><a href="#Step6-加载数据" class="headerlink" title="Step6: 加载数据"></a>Step6: 加载数据</h1><p><strong>调用方式</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, data_type=<span class="string">'train'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>load_and_cache_examples函数</strong></p>
<blockquote>
<p>如果数据已经缓存了, 就直接从缓存文件中读取出来; 否则, 利用之前编写好的 processor 类从源数据文件中读取并转换为需要训练的数据格式, 最后将数据写入缓存文件方便下次使用.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_and_cache_examples</span><span class="params">(args, task, tokenizer, data_type=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">0</span>] <span class="keyword">and</span> <span class="keyword">not</span> evaluate:</span><br><span class="line">        torch.distributed.barrier()  <span class="comment"># Make sure only the first process in distributed training process the dataset, and the others will use the cache</span></span><br><span class="line">    processor = processors[task]()</span><br><span class="line">    <span class="comment"># Load data features from cache or dataset file</span></span><br><span class="line">    cached_features_file = os.path.join(args.data_dir, <span class="string">'cached_crf-&#123;&#125;_&#123;&#125;_&#123;&#125;_&#123;&#125;'</span>.format(</span><br><span class="line">        data_type,</span><br><span class="line">        list(filter(<span class="literal">None</span>, args.model_name_or_path.split(<span class="string">'/'</span>))).pop(),</span><br><span class="line">        str(args.train_max_seq_length <span class="keyword">if</span> data_type == <span class="string">'train'</span> <span class="keyword">else</span> args.eval_max_seq_length),</span><br><span class="line">        str(task)))</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cached_features_file) <span class="keyword">and</span> <span class="keyword">not</span> args.overwrite_cache:</span><br><span class="line">        logger.info(<span class="string">"Loading features from cached file %s"</span>, cached_features_file)</span><br><span class="line">        features = torch.load(cached_features_file)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logger.info(<span class="string">"Creating features from dataset file at %s"</span>, args.data_dir)</span><br><span class="line">        label_list = processor.get_labels()</span><br><span class="line">        <span class="keyword">if</span> data_type == <span class="string">'train'</span>:</span><br><span class="line">            examples = processor.get_train_examples(args.train_path)</span><br><span class="line">        <span class="keyword">elif</span> data_type == <span class="string">'dev'</span>:</span><br><span class="line">            examples = processor.get_dev_examples(args.dev_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            examples = processor.get_test_examples(args.test_path)</span><br><span class="line">        features = convert_examples_to_features(examples=examples,</span><br><span class="line">                                                tokenizer=tokenizer,</span><br><span class="line">                                                label_list=label_list,</span><br><span class="line">                                                max_seq_length=args.train_max_seq_length <span class="keyword">if</span> data_type == <span class="string">'train'</span> \</span><br><span class="line">                                                    <span class="keyword">else</span> args.eval_max_seq_length,</span><br><span class="line">                                                cls_token_at_end=bool(args.model_type <span class="keyword">in</span> [<span class="string">"xlnet"</span>]),</span><br><span class="line">                                                pad_on_left=bool(args.model_type <span class="keyword">in</span> [<span class="string">'xlnet'</span>]),</span><br><span class="line">                                                cls_token=tokenizer.cls_token,</span><br><span class="line">                                                cls_token_segment_id=<span class="number">2</span> <span class="keyword">if</span> args.model_type <span class="keyword">in</span> [<span class="string">"xlnet"</span>] <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">                                                sep_token=tokenizer.sep_token,</span><br><span class="line">                                                <span class="comment"># pad on the left for xlnet</span></span><br><span class="line">                                                pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[<span class="number">0</span>],</span><br><span class="line">                                                pad_token_segment_id=<span class="number">4</span> <span class="keyword">if</span> args.model_type <span class="keyword">in</span> [<span class="string">'xlnet'</span>] <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">                                                )</span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">"Saving features into cached file %s"</span>, cached_features_file)</span><br><span class="line">        torch.save(features, cached_features_file)</span><br><span class="line">    <span class="comment"># Convert to Tensors and build dataset</span></span><br><span class="line">    all_input_ids = torch.tensor([f.input_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">    all_input_mask = torch.tensor([f.input_mask <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">    all_segment_ids = torch.tensor([f.segment_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">    all_label_ids = torch.tensor([f.label_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">    all_lens = torch.tensor([f.input_len <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_lens, all_label_ids)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>

<p>在这个函数中包含的关键函数是<code>convert_examples_to_features</code>, 这个函数将<code>[{words: char_list, labels: label_list}]</code> 转换为 <code>[{words: num_list, label: num_list}]</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InputFeatures</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""A single set of features of data."""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_ids, input_mask, input_len,segment_ids, label_ids)</span>:</span></span><br><span class="line">        self.input_ids = input_ids</span><br><span class="line">        self.input_mask = input_mask</span><br><span class="line">        self.segment_ids = segment_ids</span><br><span class="line">        self.label_ids = label_ids</span><br><span class="line">        self.input_len = input_len</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> str(self.to_json_string())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_dict</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Serializes this instance to a Python dictionary."""</span></span><br><span class="line">        output = copy.deepcopy(self.__dict__)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_json_string</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Serializes this instance to a JSON string."""</span></span><br><span class="line">        <span class="keyword">return</span> json.dumps(self.to_dict(), indent=<span class="number">2</span>, sort_keys=<span class="literal">True</span>) + <span class="string">"\n"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_examples_to_features</span><span class="params">(examples,label_list,max_seq_length,tokenizer,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 cls_token_at_end=False,cls_token=<span class="string">"[CLS]"</span>,cls_token_segment_id=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 sep_token=<span class="string">"[SEP]"</span>,pad_on_left=False,pad_token=<span class="number">0</span>,pad_token_segment_id=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 sequence_a_segment_id=<span class="number">0</span>,mask_padding_with_zero=True,)</span>:</span></span><br><span class="line">    <span class="string">""" Loads a data file into a list of `InputBatch`s</span></span><br><span class="line"><span class="string">        `cls_token_at_end` define the location of the CLS token:</span></span><br><span class="line"><span class="string">            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]</span></span><br><span class="line"><span class="string">            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]</span></span><br><span class="line"><span class="string">        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    label_map = &#123;label: i <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(label_list)&#125;</span><br><span class="line">    features = []</span><br><span class="line">    <span class="keyword">for</span> (ex_index, example) <span class="keyword">in</span> enumerate(examples):</span><br><span class="line">        <span class="keyword">if</span> ex_index % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">            logger.info(<span class="string">"Writing example %d of %d"</span>, ex_index, len(examples))</span><br><span class="line">        <span class="keyword">if</span> isinstance(example.text_a,list):</span><br><span class="line">            example.text_a = <span class="string">" "</span>.join(example.text_a)</span><br><span class="line">        tokens = tokenizer.tokenize(example.text_a)</span><br><span class="line">        label_ids = [label_map[x] <span class="keyword">for</span> x <span class="keyword">in</span> example.labels]</span><br><span class="line">        <span class="comment"># Account for [CLS] and [SEP] with "- 2".</span></span><br><span class="line">        special_tokens_count = <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> len(tokens) &gt; max_seq_length - special_tokens_count:</span><br><span class="line">            tokens = tokens[: (max_seq_length - special_tokens_count)]</span><br><span class="line">            label_ids = label_ids[: (max_seq_length - special_tokens_count)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The convention in BERT is:</span></span><br><span class="line">        <span class="comment"># (a) For sequence pairs:</span></span><br><span class="line">        <span class="comment">#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]</span></span><br><span class="line">        <span class="comment">#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1</span></span><br><span class="line">        <span class="comment"># (b) For single sequences:</span></span><br><span class="line">        <span class="comment">#  tokens:   [CLS] the dog is hairy . [SEP]</span></span><br><span class="line">        <span class="comment">#  type_ids:   0   0   0   0  0     0   0</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Where "type_ids" are used to indicate whether this is the first</span></span><br><span class="line">        <span class="comment"># sequence or the second sequence. The embedding vectors for `type=0` and</span></span><br><span class="line">        <span class="comment"># `type=1` were learned during pre-training and are added to the wordpiece</span></span><br><span class="line">        <span class="comment"># embedding vector (and position vector). This is not *strictly* necessary</span></span><br><span class="line">        <span class="comment"># since the [SEP] token unambiguously separates the sequences, but it makes</span></span><br><span class="line">        <span class="comment"># it easier for the model to learn the concept of sequences.</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># For classification tasks, the first vector (corresponding to [CLS]) is</span></span><br><span class="line">        <span class="comment"># used as as the "sentence vector". Note that this only makes sense because</span></span><br><span class="line">        <span class="comment"># the entire model is fine-tuned.</span></span><br><span class="line">        tokens += [sep_token]</span><br><span class="line">        label_ids += [label_map[<span class="string">'O'</span>]]</span><br><span class="line">        segment_ids = [sequence_a_segment_id] * len(tokens)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cls_token_at_end:</span><br><span class="line">            tokens += [cls_token]</span><br><span class="line">            label_ids += [label_map[<span class="string">'O'</span>]]</span><br><span class="line">            segment_ids += [cls_token_segment_id]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tokens = [cls_token] + tokens</span><br><span class="line">            label_ids = [label_map[<span class="string">'O'</span>]] + label_ids</span><br><span class="line">            segment_ids = [cls_token_segment_id] + segment_ids</span><br><span class="line"></span><br><span class="line">        input_ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line">        <span class="comment"># The mask has 1 for real tokens and 0 for padding tokens. Only real</span></span><br><span class="line">        <span class="comment"># tokens are attended to.</span></span><br><span class="line">        input_mask = [<span class="number">1</span> <span class="keyword">if</span> mask_padding_with_zero <span class="keyword">else</span> <span class="number">0</span>] * len(input_ids)</span><br><span class="line">        input_len = len(label_ids)</span><br><span class="line">        <span class="comment"># Zero-pad up to the sequence length.</span></span><br><span class="line">        padding_length = max_seq_length - len(input_ids)</span><br><span class="line">        <span class="keyword">if</span> pad_on_left:</span><br><span class="line">            input_ids = ([pad_token] * padding_length) + input_ids</span><br><span class="line">            input_mask = ([<span class="number">0</span> <span class="keyword">if</span> mask_padding_with_zero <span class="keyword">else</span> <span class="number">1</span>] * padding_length) + input_mask</span><br><span class="line">            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids</span><br><span class="line">            label_ids = ([pad_token] * padding_length) + label_ids</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            input_ids += [pad_token] * padding_length</span><br><span class="line">            input_mask += [<span class="number">0</span> <span class="keyword">if</span> mask_padding_with_zero <span class="keyword">else</span> <span class="number">1</span>] * padding_length</span><br><span class="line">            segment_ids += [pad_token_segment_id] * padding_length</span><br><span class="line">            label_ids += [pad_token] * padding_length</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> len(input_ids) == max_seq_length</span><br><span class="line">        <span class="keyword">assert</span> len(input_mask) == max_seq_length</span><br><span class="line">        <span class="keyword">assert</span> len(segment_ids) == max_seq_length</span><br><span class="line">        <span class="keyword">assert</span> len(label_ids) == max_seq_length</span><br><span class="line">        <span class="keyword">if</span> ex_index &lt; <span class="number">5</span>:</span><br><span class="line">            logger.info(<span class="string">"*** Example ***"</span>)</span><br><span class="line">            logger.info(<span class="string">"guid: %s"</span>, example.guid)</span><br><span class="line">            logger.info(<span class="string">"tokens: %s"</span>, <span class="string">" "</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> tokens]))</span><br><span class="line">            logger.info(<span class="string">"input_ids: %s"</span>, <span class="string">" "</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> input_ids]))</span><br><span class="line">            logger.info(<span class="string">"input_mask: %s"</span>, <span class="string">" "</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> input_mask]))</span><br><span class="line">            logger.info(<span class="string">"segment_ids: %s"</span>, <span class="string">" "</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> segment_ids]))</span><br><span class="line">            logger.info(<span class="string">"label_ids: %s"</span>, <span class="string">" "</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> label_ids]))</span><br><span class="line"></span><br><span class="line">        features.append(InputFeatures(input_ids=input_ids, input_mask=input_mask,input_len = input_len,</span><br><span class="line">                                      segment_ids=segment_ids, label_ids=label_ids))</span><br><span class="line">    <span class="keyword">return</span> features</span><br></pre></td></tr></table></figure>

<h1 id="Step7-模型训练"><a href="#Step7-模型训练" class="headerlink" title="Step7: 模型训练"></a>Step7: 模型训练</h1><p><strong>调用方式</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_step, tr_loss = train(args, train_dataset, model, tokenizer)</span><br></pre></td></tr></table></figure>

<h2 id="train函数编写"><a href="#train函数编写" class="headerlink" title="train函数编写"></a>train函数编写</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(args, train_dataset, model, tokenizer)</span>:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<h3 id="data-loader"><a href="#data-loader" class="headerlink" title="data_loader"></a>data_loader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, RandomSampler, SequentialSampler</span><br><span class="line">train_sampler = RandomSampler(train_dataset)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size,collate_fn=collate_fn)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.max_steps &gt; <span class="number">0</span>:</span><br><span class="line">    t_total = args.max_steps</span><br><span class="line">    args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs</span><br></pre></td></tr></table></figure>

<h3 id="Prepare-optimizer-and-schedule"><a href="#Prepare-optimizer-and-schedule" class="headerlink" title="Prepare optimizer and schedule"></a>Prepare optimizer and schedule</h3><p><strong>1.还原结构</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> callback.optimizater.adamw <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> callback.lr_scheduler <span class="keyword">import</span> get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line">no_decay = [<span class="string">"bias"</span>, <span class="string">"LayerNorm.weight"</span>]</span><br><span class="line">bert_param_optimizer = list(model.bert.named_parameters())</span><br><span class="line">crf_param_optimizer = list(model.crf.named_parameters())</span><br><span class="line">linear_param_optimizer = list(model.classifier.named_parameters())</span><br><span class="line">optimizer_grouped_parameters = [</span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> bert_param_optimizer <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">        <span class="string">'weight_decay'</span>: args.weight_decay, <span class="string">'lr'</span>: args.learning_rate&#125;,</span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> bert_param_optimizer <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">'lr'</span>: args.learning_rate&#125;,</span><br><span class="line"></span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> crf_param_optimizer <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">        <span class="string">'weight_decay'</span>: args.weight_decay, <span class="string">'lr'</span>: args.crf_learning_rate&#125;,</span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> crf_param_optimizer <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">'lr'</span>: args.crf_learning_rate&#125;,</span><br><span class="line"></span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> linear_param_optimizer <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">        <span class="string">'weight_decay'</span>: args.weight_decay, <span class="string">'lr'</span>: args.crf_learning_rate&#125;,</span><br><span class="line">    &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> linear_param_optimizer <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">'lr'</span>: args.crf_learning_rate&#125;</span><br><span class="line">]</span><br><span class="line">args.warmup_steps = int(t_total * args.warmup_proportion)</span><br><span class="line">optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)</span><br><span class="line">scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,</span><br><span class="line">                                            num_training_steps=t_total)</span><br></pre></td></tr></table></figure>

<p><strong>2.还原optimizer和scheduler参数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check if saved optimizer or scheduler states exist</span></span><br><span class="line"><span class="keyword">if</span> os.path.isfile(os.path.join(args.model_name_or_path, <span class="string">"optimizer.pt"</span>)) <span class="keyword">and</span> os.path.isfile(</span><br><span class="line">        os.path.join(args.model_name_or_path, <span class="string">"scheduler.pt"</span>)):</span><br><span class="line">    <span class="comment"># Load in optimizer and scheduler states</span></span><br><span class="line">    optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, <span class="string">"optimizer.pt"</span>)))</span><br><span class="line">    scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, <span class="string">"scheduler.pt"</span>)))</span><br></pre></td></tr></table></figure>

<p><strong>3.还原checkpoint数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">global_step = <span class="number">0</span></span><br><span class="line">steps_trained_in_current_epoch = <span class="number">0</span></span><br><span class="line"><span class="comment"># Check if continuing training from a checkpoint</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(args.model_name_or_path) <span class="keyword">and</span> <span class="string">"checkpoint"</span> <span class="keyword">in</span> args.model_name_or_path:</span><br><span class="line">    <span class="comment"># set global_step to gobal_step of last saved checkpoint from model path</span></span><br><span class="line">    global_step = int(args.model_name_or_path.split(<span class="string">"-"</span>)[<span class="number">-1</span>].split(<span class="string">"/"</span>)[<span class="number">0</span>])</span><br><span class="line">    epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)</span><br><span class="line">    steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)</span><br><span class="line">    logger.info(<span class="string">"  Continuing training from checkpoint, will skip to saved global_step"</span>)</span><br><span class="line">    logger.info(<span class="string">"  Continuing training from epoch %d"</span>, epochs_trained)</span><br><span class="line">    logger.info(<span class="string">"  Continuing training from global step %d"</span>, global_step)</span><br><span class="line">    logger.info(<span class="string">"  Will skip the first %d steps in the first epoch"</span>, steps_trained_in_current_epoch)</span><br></pre></td></tr></table></figure>

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">tr_loss, logging_loss = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">model.zero_grad()</span><br><span class="line">seed_everything(args.seed)  <span class="comment"># Added here for reproductibility (even between python 2 and 3)</span></span><br><span class="line">pbar = ProgressBar(n_total=len(train_dataloader), desc=<span class="string">'Training'</span>, num_epochs=int(args.num_train_epochs))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(int(args.num_train_epochs)):</span><br><span class="line">    pbar.reset()</span><br><span class="line">    pbar.epoch_start(current_epoch=epoch)</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> enumerate(train_dataloader):</span><br><span class="line">        <span class="comment"># Skip past any already trained steps if resuming training</span></span><br><span class="line">        <span class="keyword">if</span> steps_trained_in_current_epoch &gt; <span class="number">0</span>:</span><br><span class="line">            steps_trained_in_current_epoch -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        model.train()</span><br><span class="line">        batch = tuple(t.to(args.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">        inputs = &#123;<span class="string">"input_ids"</span>: batch[<span class="number">0</span>], <span class="string">"attention_mask"</span>: batch[<span class="number">1</span>], <span class="string">"labels"</span>: batch[<span class="number">3</span>]&#125;</span><br><span class="line">        <span class="keyword">if</span> args.model_type != <span class="string">"distilbert"</span>:</span><br><span class="line">            <span class="comment"># XLM and RoBERTa don"t use segment_ids</span></span><br><span class="line">            inputs[<span class="string">"token_type_ids"</span>] = (batch[<span class="number">2</span>] <span class="keyword">if</span> args.model_type <span class="keyword">in</span> [<span class="string">"bert"</span>, <span class="string">"xlnet"</span>] <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">        outputs = model(**inputs)</span><br><span class="line">        loss = outputs[<span class="number">0</span>]  <span class="comment"># model outputs are always tuple in pytorch-transformers (see doc)</span></span><br><span class="line">        <span class="keyword">if</span> args.gradient_accumulation_steps &gt; <span class="number">1</span>:</span><br><span class="line">            loss = loss / args.gradient_accumulation_steps</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        pbar(step, &#123;<span class="string">'loss'</span>: loss.item()&#125;)</span><br><span class="line">        tr_loss += loss.item()</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step()  <span class="comment"># Update learning rate schedule</span></span><br><span class="line">        model.zero_grad()</span><br><span class="line">        global_step += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> args.local_rank <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">0</span>] <span class="keyword">and</span> args.save_steps &gt; <span class="number">0</span> <span class="keyword">and</span> global_step % args.save_steps == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># Save model checkpoint</span></span><br><span class="line">            output_dir = os.path.join(args.output_dir, <span class="string">"checkpoint-&#123;&#125;"</span>.format(global_step))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">                os.makedirs(output_dir)</span><br><span class="line">            model_to_save = (</span><br><span class="line">                model.module <span class="keyword">if</span> hasattr(model, <span class="string">"module"</span>) <span class="keyword">else</span> model</span><br><span class="line">            )  <span class="comment"># Take care of distributed/parallel training</span></span><br><span class="line">            model_to_save.save_pretrained(output_dir)</span><br><span class="line">            torch.save(args, os.path.join(output_dir, <span class="string">"training_args.bin"</span>))</span><br><span class="line">            logger.info(<span class="string">"Saving model checkpoint to %s"</span>, output_dir)</span><br><span class="line">            tokenizer.save_vocabulary(output_dir)</span><br><span class="line">            <span class="comment"># torch.save(optimizer.state_dict(), os.path.join(output_dir, "optimizer.pt"))</span></span><br><span class="line">            torch.save(scheduler.state_dict(), os.path.join(output_dir, <span class="string">"scheduler.pt"</span>))</span><br><span class="line">            logger.info(<span class="string">"Saving optimizer and scheduler states to %s"</span>, output_dir)</span><br><span class="line">    logger.info(<span class="string">"\n"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'cuda'</span> <span class="keyword">in</span> str(args.device):</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line"><span class="keyword">return</span> global_step, tr_loss / global_step</span><br></pre></td></tr></table></figure>

<h2 id="Step8-保存最好的模型结果"><a href="#Step8-保存最好的模型结果" class="headerlink" title="Step8: 保存最好的模型结果"></a>Step8: 保存最好的模型结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">global_step, tr_loss = train(args, train_dataset, model, tokenizer)</span><br><span class="line">logger.info(<span class="string">" global_step = %s, average loss = %s"</span>, global_step, tr_loss)</span><br><span class="line"></span><br><span class="line">logger.info(<span class="string">"Saving model checkpoint to %s"</span>, args.output_dir)</span><br><span class="line"><span class="comment"># Save a trained model, configuration and tokenizer using `save_pretrained()`.</span></span><br><span class="line"><span class="comment"># They can then be reloaded using `from_pretrained()`</span></span><br><span class="line">model_to_save = (</span><br><span class="line">    model.module <span class="keyword">if</span> hasattr(model, <span class="string">"module"</span>) <span class="keyword">else</span> model</span><br><span class="line">)  <span class="comment"># Take care of distributed/parallel training</span></span><br><span class="line">model_to_save.save_pretrained(args.output_dir)</span><br><span class="line">tokenizer.save_vocabulary(args.output_dir)</span><br><span class="line"><span class="comment"># Good practice: save your training arguments together with the trained model</span></span><br><span class="line">torch.save(args, os.path.join(args.output_dir, <span class="string">"training_args.bin"</span>))</span><br></pre></td></tr></table></figure>

<h2 id="Step9-在dev集上评估"><a href="#Step9-在dev集上评估" class="headerlink" title="Step9: 在dev集上评估"></a>Step9: 在dev集上评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line">results = &#123;&#125;</span><br><span class="line">checkpoints = [args.output_dir]</span><br><span class="line"><span class="keyword">if</span> args.eval_all_checkpoints:</span><br><span class="line">    checkpoints = list(</span><br><span class="line">        os.path.dirname(c) <span class="keyword">for</span> c <span class="keyword">in</span> sorted(glob.glob(args.output_dir + <span class="string">"/**/"</span> + WEIGHTS_NAME, recursive=<span class="literal">True</span>))</span><br><span class="line">    )</span><br><span class="line">    logging.getLogger(<span class="string">"pytorch_transformers.modeling_utils"</span>).setLevel(logging.WARN)  <span class="comment"># Reduce logging</span></span><br><span class="line">logger.info(<span class="string">"Evaluate the following checkpoints: %s"</span>, checkpoints)</span><br><span class="line"><span class="keyword">for</span> checkpoint <span class="keyword">in</span> checkpoints:</span><br><span class="line">    global_step = checkpoint.split(<span class="string">"-"</span>)[<span class="number">-1</span>] <span class="keyword">if</span> len(checkpoints) &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    prefix = checkpoint.split(<span class="string">'/'</span>)[<span class="number">-1</span>] <span class="keyword">if</span> checkpoint.find(<span class="string">'checkpoint'</span>) != <span class="number">-1</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    model = model_class.from_pretrained(checkpoint, config=config)</span><br><span class="line">    model.to(args.device)</span><br><span class="line">    result = evaluate(args, model, tokenizer, prefix=prefix)</span><br><span class="line">    <span class="keyword">if</span> global_step:</span><br><span class="line">        result = &#123;<span class="string">"&#123;&#125;_&#123;&#125;"</span>.format(global_step, k): v <span class="keyword">for</span> k, v <span class="keyword">in</span> result.items()&#125;</span><br><span class="line">    results.update(result)</span><br><span class="line">output_eval_file = os.path.join(args.output_dir, <span class="string">"eval_results.txt"</span>)</span><br><span class="line"><span class="keyword">with</span> open(output_eval_file, <span class="string">"w"</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> sorted(results.keys()):</span><br><span class="line">        writer.write(<span class="string">"&#123;&#125; = &#123;&#125;\n"</span>.format(key, str(results[key])))</span><br></pre></td></tr></table></figure>

<p><strong>evaluate函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(args, model, tokenizer, prefix=<span class="string">""</span>)</span>:</span></span><br><span class="line">    metric = SeqEntityScore(args.id2label, markup=args.markup)</span><br><span class="line">    eval_output_dir = args.output_dir</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(eval_output_dir) <span class="keyword">and</span> args.local_rank <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">0</span>]:</span><br><span class="line">        os.makedirs(eval_output_dir)</span><br><span class="line">    eval_dataset = load_and_cache_examples(args, args.task_name, tokenizer, data_type=<span class="string">'dev'</span>)</span><br><span class="line">    args.eval_batch_size = args.per_gpu_eval_batch_size * max(<span class="number">1</span>, args.n_gpu)</span><br><span class="line">    <span class="comment"># Note that DistributedSampler samples randomly</span></span><br><span class="line">    eval_sampler = SequentialSampler(eval_dataset) <span class="keyword">if</span> args.local_rank == <span class="number">-1</span> <span class="keyword">else</span> DistributedSampler(eval_dataset)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size,</span><br><span class="line">                                 collate_fn=collate_fn)</span><br><span class="line">    <span class="comment"># Eval!</span></span><br><span class="line">    logger.info(<span class="string">"***** Running evaluation %s *****"</span>, prefix)</span><br><span class="line">    logger.info(<span class="string">"  Num examples = %d"</span>, len(eval_dataset))</span><br><span class="line">    logger.info(<span class="string">"  Batch size = %d"</span>, args.eval_batch_size)</span><br><span class="line">    eval_loss = <span class="number">0.0</span></span><br><span class="line">    nb_eval_steps = <span class="number">0</span></span><br><span class="line">    pbar = ProgressBar(n_total=len(eval_dataloader), desc=<span class="string">"Evaluating"</span>)</span><br><span class="line">    <span class="keyword">if</span> isinstance(model, nn.DataParallel):</span><br><span class="line">        model = model.module</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> enumerate(eval_dataloader):</span><br><span class="line">        model.eval()</span><br><span class="line">        batch = tuple(t.to(args.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            inputs = &#123;<span class="string">"input_ids"</span>: batch[<span class="number">0</span>], <span class="string">"attention_mask"</span>: batch[<span class="number">1</span>], <span class="string">"labels"</span>: batch[<span class="number">3</span>]&#125;</span><br><span class="line">            <span class="keyword">if</span> args.model_type != <span class="string">"distilbert"</span>:</span><br><span class="line">                <span class="comment"># XLM and RoBERTa don"t use segment_ids</span></span><br><span class="line">                inputs[<span class="string">"token_type_ids"</span>] = (batch[<span class="number">2</span>] <span class="keyword">if</span> args.model_type <span class="keyword">in</span> [<span class="string">"bert"</span>, <span class="string">"xlnet"</span>] <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">            outputs = model(**inputs)</span><br><span class="line">            tmp_eval_loss, logits = outputs[:<span class="number">2</span>]</span><br><span class="line">            tags = model.crf.decode(logits, inputs[<span class="string">'attention_mask'</span>])</span><br><span class="line">        <span class="keyword">if</span> args.n_gpu &gt; <span class="number">1</span>:</span><br><span class="line">            tmp_eval_loss = tmp_eval_loss.mean()  <span class="comment"># mean() to average on multi-gpu parallel evaluating</span></span><br><span class="line">        eval_loss += tmp_eval_loss.item()</span><br><span class="line">        nb_eval_steps += <span class="number">1</span></span><br><span class="line">        out_label_ids = inputs[<span class="string">'labels'</span>].cpu().numpy().tolist()</span><br><span class="line">        input_lens = batch[<span class="number">4</span>].cpu().numpy().tolist()</span><br><span class="line">        tags = tags.squeeze(<span class="number">0</span>).cpu().numpy().tolist()</span><br><span class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(out_label_ids):</span><br><span class="line">            temp_1 = []</span><br><span class="line">            temp_2 = []</span><br><span class="line">            <span class="keyword">for</span> j, m <span class="keyword">in</span> enumerate(label):</span><br><span class="line">                <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">elif</span> j == input_lens[i] - <span class="number">1</span>:</span><br><span class="line">                    metric.update(pred_paths=[temp_2], label_paths=[temp_1])</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    temp_1.append(args.id2label[out_label_ids[i][j]])</span><br><span class="line">                    temp_2.append(args.id2label[tags[i][j]])</span><br><span class="line">        pbar(step)</span><br><span class="line">    logger.info(<span class="string">"\n"</span>)</span><br><span class="line">    eval_loss = eval_loss / nb_eval_steps</span><br><span class="line">    eval_info, entity_info = metric.result()</span><br><span class="line">    results = &#123;<span class="string">f'<span class="subst">&#123;key&#125;</span>'</span>: value <span class="keyword">for</span> key, value <span class="keyword">in</span> eval_info.items()&#125;</span><br><span class="line">    results[<span class="string">'loss'</span>] = eval_loss</span><br><span class="line">    logger.info(<span class="string">"***** Eval results %s *****"</span>, prefix)</span><br><span class="line">    info = <span class="string">"-"</span>.join([<span class="string">f' <span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;value:<span class="number">.4</span>f&#125;</span> '</span> <span class="keyword">for</span> key, value <span class="keyword">in</span> results.items()])</span><br><span class="line">    logger.info(info)</span><br><span class="line">    logger.info(<span class="string">"***** Entity results %s *****"</span>, prefix)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> sorted(entity_info.keys()):</span><br><span class="line">        logger.info(<span class="string">"******* %s results ********"</span> % key)</span><br><span class="line">        info = <span class="string">"-"</span>.join([<span class="string">f' <span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;value:<span class="number">.4</span>f&#125;</span> '</span> <span class="keyword">for</span> key, value <span class="keyword">in</span> entity_info[key].items()])</span><br><span class="line">        logger.info(info)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<p>其中比较关键的两个部件是<code>SeqEntityScore</code>(准确率计算类)和<code>crf.decode</code>(解码CRF结果矩阵的到最优tag路径).</p>
<p><strong>SeqEntityScore</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SeqEntityScore</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, id2label,markup=<span class="string">'bios'</span>)</span>:</span></span><br><span class="line">        self.id2label = id2label</span><br><span class="line">        self.markup = markup</span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.origins = []</span><br><span class="line">        self.founds = []</span><br><span class="line">        self.rights = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span><span class="params">(self, origin, found, right)</span>:</span></span><br><span class="line">        recall = <span class="number">0</span> <span class="keyword">if</span> origin == <span class="number">0</span> <span class="keyword">else</span> (right / origin)</span><br><span class="line">        precision = <span class="number">0</span> <span class="keyword">if</span> found == <span class="number">0</span> <span class="keyword">else</span> (right / found)</span><br><span class="line">        f1 = <span class="number">0.</span> <span class="keyword">if</span> recall + precision == <span class="number">0</span> <span class="keyword">else</span> (<span class="number">2</span> * precision * recall) / (precision + recall)</span><br><span class="line">        <span class="keyword">return</span> recall, precision, f1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">result</span><span class="params">(self)</span>:</span></span><br><span class="line">        class_info = &#123;&#125;</span><br><span class="line">        origin_counter = Counter([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.origins])</span><br><span class="line">        found_counter = Counter([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.founds])</span><br><span class="line">        right_counter = Counter([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.rights])</span><br><span class="line">        <span class="keyword">for</span> type_, count <span class="keyword">in</span> origin_counter.items():</span><br><span class="line">            origin = count</span><br><span class="line">            found = found_counter.get(type_, <span class="number">0</span>)</span><br><span class="line">            right = right_counter.get(type_, <span class="number">0</span>)</span><br><span class="line">            recall, precision, f1 = self.compute(origin, found, right)</span><br><span class="line">            class_info[type_] = &#123;<span class="string">"acc"</span>: round(precision, <span class="number">4</span>), <span class="string">'recall'</span>: round(recall, <span class="number">4</span>), <span class="string">'f1'</span>: round(f1, <span class="number">4</span>)&#125;</span><br><span class="line">        origin = len(self.origins)</span><br><span class="line">        found = len(self.founds)</span><br><span class="line">        right = len(self.rights)</span><br><span class="line">        recall, precision, f1 = self.compute(origin, found, right)</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'acc'</span>: precision, <span class="string">'recall'</span>: recall, <span class="string">'f1'</span>: f1&#125;, class_info</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, label_paths, pred_paths)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        labels_paths: [[],[],[],....]</span></span><br><span class="line"><span class="string">        pred_paths: [[],[],[],.....]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param label_paths:</span></span><br><span class="line"><span class="string">        :param pred_paths:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        Example:</span></span><br><span class="line"><span class="string">            &gt;&gt;&gt; labels_paths = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]</span></span><br><span class="line"><span class="string">            &gt;&gt;&gt; pred_paths = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">for</span> label_path, pre_path <span class="keyword">in</span> zip(label_paths, pred_paths):</span><br><span class="line">            label_entities = get_entities(label_path, self.id2label,self.markup)</span><br><span class="line">            pre_entities = get_entities(pre_path, self.id2label,self.markup)</span><br><span class="line">            self.origins.extend(label_entities)</span><br><span class="line">            self.founds.extend(pre_entities)</span><br><span class="line">            self.rights.extend([pre_entity <span class="keyword">for</span> pre_entity <span class="keyword">in</span> pre_entities <span class="keyword">if</span> pre_entity <span class="keyword">in</span> label_entities])</span><br></pre></td></tr></table></figure>

<p><strong>crf.decode</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_viterbi_decode</span><span class="params">(self, emissions: torch.FloatTensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                        mask: torch.ByteTensor,</span></span></span><br><span class="line"><span class="function"><span class="params">                        pad_tag: Optional[int] = None)</span> -&gt; List[List[int]]:</span></span><br><span class="line">        <span class="comment"># emissions: (seq_length, batch_size, num_tags)</span></span><br><span class="line">        <span class="comment"># mask: (seq_length, batch_size)</span></span><br><span class="line">        <span class="comment"># return: (batch_size, seq_length)</span></span><br><span class="line">        <span class="keyword">if</span> pad_tag <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            pad_tag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        device = emissions.device</span><br><span class="line">        seq_length, batch_size = mask.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Start transition and first emission</span></span><br><span class="line">        <span class="comment"># shape: (batch_size, num_tags)</span></span><br><span class="line">        score = self.start_transitions + emissions[<span class="number">0</span>]</span><br><span class="line">        history_idx = torch.zeros((seq_length, batch_size, self.num_tags),</span><br><span class="line">                                  dtype=torch.long, device=device)</span><br><span class="line">        oor_idx = torch.zeros((batch_size, self.num_tags),</span><br><span class="line">                              dtype=torch.long, device=device)</span><br><span class="line">        oor_tag = torch.full((seq_length, batch_size), pad_tag,</span><br><span class="line">                             dtype=torch.long, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># - score is a tensor of size (batch_size, num_tags) where for every batch,</span></span><br><span class="line">        <span class="comment">#   value at column j stores the score of the best tag sequence so far that ends</span></span><br><span class="line">        <span class="comment">#   with tag j</span></span><br><span class="line">        <span class="comment"># - history_idx saves where the best tags candidate transitioned from; this is used</span></span><br><span class="line">        <span class="comment">#   when we trace back the best tag sequence</span></span><br><span class="line">        <span class="comment"># - oor_idx saves the best tags candidate transitioned from at the positions</span></span><br><span class="line">        <span class="comment">#   where mask is 0, i.e. out of range (oor)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Viterbi algorithm recursive case: we compute the score of the best tag sequence</span></span><br><span class="line">        <span class="comment"># for every possible next tag</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, seq_length):</span><br><span class="line">            <span class="comment"># Broadcast viterbi score for every possible next tag</span></span><br><span class="line">            <span class="comment"># shape: (batch_size, num_tags, 1)</span></span><br><span class="line">            broadcast_score = score.unsqueeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Broadcast emission score for every possible current tag</span></span><br><span class="line">            <span class="comment"># shape: (batch_size, 1, num_tags)</span></span><br><span class="line">            broadcast_emission = emissions[i].unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute the score tensor of size (batch_size, num_tags, num_tags) where</span></span><br><span class="line">            <span class="comment"># for each sample, entry at row i and column j stores the score of the best</span></span><br><span class="line">            <span class="comment"># tag sequence so far that ends with transitioning from tag i to tag j and emitting</span></span><br><span class="line">            <span class="comment"># shape: (batch_size, num_tags, num_tags)</span></span><br><span class="line">            next_score = broadcast_score + self.transitions + broadcast_emission</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Find the maximum score over all possible current tag</span></span><br><span class="line">            <span class="comment"># shape: (batch_size, num_tags)</span></span><br><span class="line">            next_score, indices = next_score.max(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Set score to the next score if this timestep is valid (mask == 1)</span></span><br><span class="line">            <span class="comment"># and save the index that produces the next score</span></span><br><span class="line">            <span class="comment"># shape: (batch_size, num_tags)</span></span><br><span class="line">            score = torch.where(mask[i].unsqueeze(<span class="number">-1</span>), next_score, score)</span><br><span class="line">            indices = torch.where(mask[i].unsqueeze(<span class="number">-1</span>), indices, oor_idx)</span><br><span class="line">            history_idx[i - <span class="number">1</span>] = indices</span><br><span class="line"></span><br><span class="line">        <span class="comment"># End transition score</span></span><br><span class="line">        <span class="comment"># shape: (batch_size, num_tags)</span></span><br><span class="line">        end_score = score + self.end_transitions</span><br><span class="line">        _, end_tag = end_score.max(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shape: (batch_size,)</span></span><br><span class="line">        seq_ends = mask.long().sum(dim=<span class="number">0</span>) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># insert the best tag at each sequence end (last position with mask == 1)</span></span><br><span class="line">        history_idx = history_idx.transpose(<span class="number">1</span>, <span class="number">0</span>).contiguous()</span><br><span class="line">        history_idx.scatter_(<span class="number">1</span>, seq_ends.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(<span class="number">-1</span>, <span class="number">1</span>, self.num_tags),</span><br><span class="line">                             end_tag.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(<span class="number">-1</span>, <span class="number">1</span>, self.num_tags))</span><br><span class="line">        history_idx = history_idx.transpose(<span class="number">1</span>, <span class="number">0</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The most probable path for each sequence</span></span><br><span class="line">        best_tags_arr = torch.zeros((seq_length, batch_size),</span><br><span class="line">                                    dtype=torch.long, device=device)</span><br><span class="line">        best_tags = torch.zeros(batch_size, <span class="number">1</span>, dtype=torch.long, device=device)</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(seq_length - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            best_tags = torch.gather(history_idx[idx], <span class="number">1</span>, best_tags)</span><br><span class="line">            best_tags_arr[idx] = best_tags.data.view(batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.where(mask, best_tags_arr, oor_tag).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Step9-在test集上预测"><a href="#Step9-在test集上预测" class="headerlink" title="Step9: 在test集上预测"></a>Step9: 在test集上预测</h2><blockquote>
<p>与evaluate基本一致</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/15/EM%E7%AE%97%E6%B3%95/" rel="prev" title="EM算法">
      <i class="fa fa-chevron-left"></i> EM算法
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/05/03/Deep-Learning-Review-2015/" rel="next" title="Deep Learning Review 2015">
      Deep Learning Review 2015 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MDY4OC8yNzE3MQ"></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Llunch</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/next-boot.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":false},"rect":"opacity:0.7","log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
