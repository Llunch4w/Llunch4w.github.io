<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"llunch4w.github.io","root":"/","scheme":"Pisces","version":"8.0.0-rc.3","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="^ _ ^">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Reaeding Comprehension Survey">
<meta property="og:url" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/index.html">
<meta property="og:site_name" content="摸鱼的Llunch">
<meta property="og:description" content="^ _ ^">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/general_architecture.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/typical_method.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/word-level-encoding.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/sentence-level-encoding.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/cnn-encoding.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/transformer-encoding.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/unidirectional_attention.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/bidirectional_attention.png">
<meta property="og:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/f1.png">
<meta property="article:published_time" content="2022-07-19T06:15:38.000Z">
<meta property="article:modified_time" content="2022-07-21T06:53:51.500Z">
<meta property="article:author" content="Llunch">
<meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/general_architecture.png">

<link rel="canonical" href="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Machine Reaeding Comprehension Survey | 摸鱼的Llunch</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before, .use-motion .logo-line-after {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line toggle-line-first"></span>
        <span class="toggle-line toggle-line-middle"></span>
        <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line-before"></i>
      <h1 class="site-title">摸鱼的Llunch</h1>
      <i class="logo-line-after"></i>
    </a>
      <p class="site-subtitle" itemprop="description">但行好事，莫问前程</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Task"><span class="nav-number">1.</span> <span class="nav-text">Task</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Cloze-Tests"><span class="nav-number">1.1.</span> <span class="nav-text">Cloze Tests</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-Choice"><span class="nav-number">1.2.</span> <span class="nav-text">Multiple Choice</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Span-Extraction"><span class="nav-number">1.3.</span> <span class="nav-text">Span Extraction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Free-Answering"><span class="nav-number">1.4.</span> <span class="nav-text">Free Answering</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-learning-based-Method"><span class="nav-number">2.</span> <span class="nav-text">Deep-learning based Method</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#General-Architecture"><span class="nav-number">2.1.</span> <span class="nav-text">General Architecture</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Typical-Deep-learning-Methods"><span class="nav-number">2.2.</span> <span class="nav-text">Typical Deep-learning Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Embeddings"><span class="nav-number">2.2.1.</span> <span class="nav-text">Embeddings</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Conventional-Word-Representation"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">Conventional Word Representation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#One-Hot"><span class="nav-number">2.2.1.1.1.</span> <span class="nav-text">One-Hot</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Distributed-Word-Representation"><span class="nav-number">2.2.1.1.2.</span> <span class="nav-text">Distributed Word Representation</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pre-trained-Contextualized-Word-Representation"><span class="nav-number">2.2.1.2.</span> <span class="nav-text">Pre-trained Contextualized Word Representation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#CoVE"><span class="nav-number">2.2.1.2.1.</span> <span class="nav-text">CoVE</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ELMo"><span class="nav-number">2.2.1.2.2.</span> <span class="nav-text">ELMo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#GPT"><span class="nav-number">2.2.1.2.3.</span> <span class="nav-text">GPT</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#BERT"><span class="nav-number">2.2.1.2.4.</span> <span class="nav-text">BERT</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multiple-Granularity"><span class="nav-number">2.2.1.3.</span> <span class="nav-text">Multiple Granularity</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Character-Embeddings"><span class="nav-number">2.2.1.3.1.</span> <span class="nav-text">Character Embeddings</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Part-of-Speech-Tags"><span class="nav-number">2.2.1.3.2.</span> <span class="nav-text">Part-of-Speech Tags</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Name-Entity-Tags"><span class="nav-number">2.2.1.3.3.</span> <span class="nav-text">Name-Entity Tags</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Binary-Feature-of-Exact-Match-EM"><span class="nav-number">2.2.1.3.4.</span> <span class="nav-text">Binary Feature of Exact Match (EM)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Query-Category"><span class="nav-number">2.2.1.3.5.</span> <span class="nav-text">Query-Category</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Extraction"><span class="nav-number">2.2.2.</span> <span class="nav-text">Feature Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Recurrent-Neural-Networks"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">Recurrent Neural Networks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Convolution-Neural-Networks"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">Convolution Neural Networks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Transformer"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">Transformer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Context-Question-Interaction"><span class="nav-number">2.2.3.</span> <span class="nav-text">Context-Question Interaction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Unidirectional-Attention"><span class="nav-number">2.2.3.1.</span> <span class="nav-text">Unidirectional Attention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bidirectional-Attention"><span class="nav-number">2.2.3.2.</span> <span class="nav-text">Bidirectional Attention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#One-Hop-Interaction"><span class="nav-number">2.2.3.3.</span> <span class="nav-text">One-Hop Interaction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Hop-Interaction"><span class="nav-number">2.2.3.4.</span> <span class="nav-text">Multi-Hop Interaction</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Answer-Prediction"><span class="nav-number">2.2.4.</span> <span class="nav-text">Answer Prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Word-Predictor"><span class="nav-number">2.2.4.1.</span> <span class="nav-text">Word Predictor</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Option-Selector"><span class="nav-number">2.2.4.2.</span> <span class="nav-text">Option Selector</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Span-Extractor"><span class="nav-number">2.2.4.3.</span> <span class="nav-text">Span Extractor</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Answer-Generator"><span class="nav-number">2.2.4.4.</span> <span class="nav-text">Answer Generator</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Additional-Tricks"><span class="nav-number">2.3.</span> <span class="nav-text">Additional Tricks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reinforcement-Learning"><span class="nav-number">2.3.1.</span> <span class="nav-text">Reinforcement Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Answer-Ranker"><span class="nav-number">2.3.2.</span> <span class="nav-text">Answer Ranker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sentence-Selector"><span class="nav-number">2.3.3.</span> <span class="nav-text">Sentence Selector</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dataset-and-Evaluation-Metrics"><span class="nav-number">3.</span> <span class="nav-text">Dataset and Evaluation Metrics</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset"><span class="nav-number">3.1.</span> <span class="nav-text">Dataset</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cloze-Tests-Datasets"><span class="nav-number">3.1.1.</span> <span class="nav-text">Cloze Tests Datasets</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiple-Choice-Dataset"><span class="nav-number">3.1.2.</span> <span class="nav-text">Multiple-Choice Dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Span-Extraction-Dataset"><span class="nav-number">3.1.3.</span> <span class="nav-text">Span Extraction Dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Free-Answering-Datasets"><span class="nav-number">3.1.4.</span> <span class="nav-text">Free Answering Datasets</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluation-Metrics"><span class="nav-number">3.2.</span> <span class="nav-text">Evaluation Metrics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Accuracy"><span class="nav-number">3.2.1.</span> <span class="nav-text">Accuracy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#F1-Score"><span class="nav-number">3.2.2.</span> <span class="nav-text">F1 Score</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROUGE-L"><span class="nav-number">3.2.3.</span> <span class="nav-text">ROUGE-L</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BLEU"><span class="nav-number">3.2.4.</span> <span class="nav-text">BLEU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#New-Trends"><span class="nav-number">4.</span> <span class="nav-text">New Trends</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Knowledge-Based-Machine-Reading-Comprehension"><span class="nav-number">4.1.</span> <span class="nav-text">Knowledge-Based Machine Reading Comprehension</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Relevant-External-Knowledge-Retrieval"><span class="nav-number">4.1.1.</span> <span class="nav-text">Relevant External Knowledge Retrieval</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#External-Knowledge-Integration"><span class="nav-number">4.1.2.</span> <span class="nav-text">External Knowledge Integration</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Machine-Reading-Comprehension-with-Unanswerable-Questions"><span class="nav-number">4.2.</span> <span class="nav-text">Machine Reading Comprehension with Unanswerable Questions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Unanswerable-Questions"><span class="nav-number">4.2.1.</span> <span class="nav-text">Unanswerable Questions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Unanswerable-Question-Detection"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">Unanswerable Question Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Plausible-貌似真实的-Answer-Discrimination"><span class="nav-number">4.2.1.2.</span> <span class="nav-text">Plausible(貌似真实的) Answer Discrimination</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-Passage-Machine-Reading-Comprehension"><span class="nav-number">4.3.</span> <span class="nav-text">Multi-Passage Machine Reading Comprehension</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Massive-Document-Corpus"><span class="nav-number">4.3.1.</span> <span class="nav-text">Massive Document Corpus</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Noisy-Document-Retrieval"><span class="nav-number">4.3.2.</span> <span class="nav-text">Noisy Document Retrieval</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#No-Answer"><span class="nav-number">4.3.3.</span> <span class="nav-text">No Answer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiple-Answers"><span class="nav-number">4.3.4.</span> <span class="nav-text">Multiple Answers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Evidence-Aggregation"><span class="nav-number">4.3.5.</span> <span class="nav-text">Evidence Aggregation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conversational-Machine-Reading-Comprehension"><span class="nav-number">4.4.</span> <span class="nav-text">Conversational Machine Reading Comprehension</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Conversational-History"><span class="nav-number">4.4.1.</span> <span class="nav-text">Conversational History</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Coreference-Resolution-指代消解"><span class="nav-number">4.4.2.</span> <span class="nav-text">Coreference Resolution(指代消解)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Open-Issues"><span class="nav-number">5.</span> <span class="nav-text">Open Issues</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Llunch"
      src="/images/me.jpg">
  <p class="site-author-name" itemprop="name">Llunch</p>
  <div class="site-description" itemprop="description">Laugh through the night</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">120</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">79</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Llunch4w" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Llunch4w" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://llunch4w.github.io/2022/07/19/Machine-Reaeding-Comprehension-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me.jpg">
      <meta itemprop="name" content="Llunch">
      <meta itemprop="description" content="Laugh through the night">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="摸鱼的Llunch">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Machine Reaeding Comprehension Survey
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-07-19 14:15:38" itemprop="dateCreated datePublished" datetime="2022-07-19T14:15:38+08:00">2022-07-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-07-21 14:53:51" itemprop="dateModified" datetime="2022-07-21T14:53:51+08:00">2022-07-21</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote class="blockquote-center">
<p>^ _ ^ </p>

</blockquote>
<a id="more"></a>

<h1 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h1><p><strong>Difinition of machine reading compreahension</strong> </p>
<blockquote>
<p>Given the context $C$ and question $Q$, machine reading comprehension tasks ask the model to give the correct answer $A$ to the question $Q$ by learning the function $F$ such that $A = F(C, Q)$</p>
</blockquote>
<h2 id="Cloze-Tests"><a href="#Cloze-Tests" class="headerlink" title="Cloze Tests"></a>Cloze Tests</h2><blockquote>
<p>Given the context $C$, from which a word or an entity $A(A \in C)$ is removed, the cloze test ask the model to fill in the blank woth the right word or entity A by learning the function $F$ such that $A=F(C-{A})$</p>
</blockquote>
<h2 id="Multiple-Choice"><a href="#Multiple-Choice" class="headerlink" title="Multiple Choice"></a>Multiple Choice</h2><blockquote>
<p>Given the context $C$, the question $Q$ and a list of candidate answers $A={A_1, A_2, \cdots, A_n}$, the multiple-choice task is to select the correct answer $A_i$ from $A(A_i \in A)$ by learning function F such that $A_i=F(C, Q, A)$</p>
</blockquote>
<h2 id="Span-Extraction"><a href="#Span-Extraction" class="headerlink" title="Span Extraction"></a>Span Extraction</h2><blockquote>
<p>Given the context $C$, which consists of $n$ tokens, that is $C={ t_1, t_2, \cdots, t_n }$, and the question $Q$, the span extraction task requires extracting the continuous subsequence  $A$ = { $t_i, t_{i+1}, \cdots, t_{i+k}$ } from context $C$ as the correct answer to question $Q$ by learning function $F$ such that $A=F(C, Q)$</p>
</blockquote>
<h2 id="Free-Answering"><a href="#Free-Answering" class="headerlink" title="Free Answering"></a>Free Answering</h2><blockquote>
<p>Given the context $C$ and the question $Q$, the correct answer $A$ in free answering task may not be subsequence in the original context $C$, namely either $A \in C$ or $A \notin C$. The task requires predicting the correct answer $A$ by learning the function $F$ such that $A = F(C, Q)$.</p>
</blockquote>
<h1 id="Deep-learning-based-Method"><a href="#Deep-learning-based-Method" class="headerlink" title="Deep-learning based Method"></a>Deep-learning based Method</h1><h2 id="General-Architecture"><a href="#General-Architecture" class="headerlink" title="General Architecture"></a>General Architecture</h2><p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/general_architecture.png" alt></p>
<ol>
<li>Embeddings: change input words into fixed-length vectors.<ul>
<li>Classical word representation method include One-hot; Word2vec; Glove; Fastext.</li>
<li>Sometimes combined with other linguistic features, i.e., part-of-speech, name entity, and question category.</li>
</ul>
</li>
<li>Feature Extraction: Mine contextual features from context and question embeddings<ul>
<li>This module is aimed at extracting more contextual information.</li>
<li>Some typical deep neural networks such as CNN, RNN are used.</li>
</ul>
</li>
<li>Context-Question Interation: find out which parts in the context are more important to answering the question.<ul>
<li>The attention mechanism, unidirectional or bidirectional, is widely used in this module to emphasize parts of the context relevant to the query.</li>
<li>Sometimes involves multiple hops, which simulates the rereading process of human comprehension.</li>
</ul>
</li>
<li>Answer Prediction: this module is highly related to different tasks<ul>
<li>Generation techniques are used in this module for the free answering task</li>
</ul>
</li>
</ol>
<h2 id="Typical-Deep-learning-Methods"><a href="#Typical-Deep-learning-Methods" class="headerlink" title="Typical Deep-learning Methods"></a>Typical Deep-learning Methods</h2><p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/typical_method.png" alt></p>
<h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><h4 id="Conventional-Word-Representation"><a href="#Conventional-Word-Representation" class="headerlink" title="Conventional Word Representation"></a>Conventional Word Representation</h4><h5 id="One-Hot"><a href="#One-Hot" class="headerlink" title="One-Hot"></a>One-Hot</h5><ul>
<li>Using binary vector to represent word, and the size of vector is equal to the size of vocabulary.</li>
<li>Drawbacks:<ul>
<li>Sparse and may cause curse of dimensionality with increased vocabulary.</li>
<li>Cannot represent relationships among words.</li>
</ul>
</li>
</ul>
<h5 id="Distributed-Word-Representation"><a href="#Distributed-Word-Representation" class="headerlink" title="Distributed Word Representation"></a>Distributed Word Representation</h5><ul>
<li>Encodes words into continuous low-dimensional vectors, which reveals the correlation of words.</li>
<li>Popular techniques to generate distrubuted word representation: Word2Vec、GloVe.</li>
<li>Drawback: Cannot efficiently mine contextual information.</li>
</ul>
<h4 id="Pre-trained-Contextualized-Word-Representation"><a href="#Pre-trained-Contextualized-Word-Representation" class="headerlink" title="Pre-trained Contextualized Word Representation"></a>Pre-trained Contextualized Word Representation</h4><ul>
<li>A vector produced by the distributed word representation of one word is constant regardless of different contexts.</li>
<li>Contextualized word representations, which are pre-trained with large corpora in advance and then directly used as conventional word representations or fine-tuned according to the specific tasks.</li>
</ul>
<h5 id="CoVE"><a href="#CoVE" class="headerlink" title="CoVE"></a>CoVE</h5><ul>
<li>The output of the encoder can be regarded as context vectors (CoVE).    </li>
<li>Concatenate CoVE of another task and embeddings of this task and feed them through the decoder.</li>
<li>Drawbacks: Another task(e.g. Machine Translation) needs a large parallel corpus. Its performance will degrade if the training corpus is not adequate.</li>
</ul>
<h5 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h5><ul>
<li>Embeddings from language models (ELMo)</li>
<li>First pre-train a bidirectional language model (biLM) with a large text corpus, then collapsing outputs of all biLM<br>layers into a single vector with a task-specific weighting.</li>
</ul>
<h5 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h5><ul>
<li>Generative pre-training (GPT)</li>
<li>A semi-supervised approach combining unsupervised pre-training and supervised fine-tuning. </li>
<li>The basic component of GPT is a multi-layer transformer decoder that mainly uses multi-head self-attention to train the language model.</li>
</ul>
<h5 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h5><ul>
<li>Bidirectional encoder representation from transformers (BERT).</li>
<li>With the masked language model (MLM) and next-sentence prediction task, BERT can pre-train deep contextualized representations with a bidirectional transformer.</li>
</ul>
<h4 id="Multiple-Granularity"><a href="#Multiple-Granularity" class="headerlink" title="Multiple Granularity"></a>Multiple Granularity</h4><ul>
<li>Word-level embeddings pre-trained by Word2Vec or GloVe cannot encode rich syntactic and linguistic information, such as part-of-speech, affixes, and grammar.</li>
</ul>
<h5 id="Character-Embeddings"><a href="#Character-Embeddings" class="headerlink" title="Character Embeddings"></a>Character Embeddings</h5><ul>
<li>Character embeddings represent words at the character level.</li>
<li>Character embeddings can be encoded with bidirectional LSTMs. For each word, the outputs of the last hidden state are considered to be its character-level representation.</li>
<li>Moreover, word-level and character-level embeddings can be combined dynamically with a fine-grained gating mechanism.</li>
</ul>
<h5 id="Part-of-Speech-Tags"><a href="#Part-of-Speech-Tags" class="headerlink" title="Part-of-Speech Tags"></a>Part-of-Speech Tags</h5><ul>
<li>A part-of-speech (POS) is a particular grammatical class of words, such as nouns, adjectives, or verb.</li>
<li>Labeling POS tags in NLP tasks can illustrate complex characteristics of word use and in turn contribute to disambiguation.</li>
</ul>
<h5 id="Name-Entity-Tags"><a href="#Name-Entity-Tags" class="headerlink" title="Name-Entity Tags"></a>Name-Entity Tags</h5><ul>
<li>Name entity, a concept in information retrieval, refers to a real-world object, such as a person, location, or organizations, with a proper name.</li>
<li>When asking about such objects, name entities are probable answer candidates.</li>
<li>The method of encoding name-entity tags is similar to that of POS tags.</li>
</ul>
<h5 id="Binary-Feature-of-Exact-Match-EM"><a href="#Binary-Feature-of-Exact-Match-EM" class="headerlink" title="Binary Feature of Exact Match (EM)"></a>Binary Feature of Exact Match (EM)</h5><ul>
<li>This feature measures whether a context word is in the question.</li>
<li>More loosely, partial matching to measure the correlation between context words and question words. For instance, “teacher” can be partially matched with “teach”.</li>
</ul>
<h5 id="Query-Category"><a href="#Query-Category" class="headerlink" title="Query-Category"></a>Query-Category</h5><ul>
<li>The types of questions (what, where, who, when, why, how) can usually provide clues to search for the answer.</li>
<li>First obtain query types by counting the key word frequency. Then the question type information is encoded to one-hot vectors and stored in a table. For each query, they look up the table and use a feed-forward neural network for projection.</li>
</ul>
<h3 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h3><ul>
<li>The feature extraction module is often placed after the embedding layer to extract features of the context and question separately.</li>
<li>It further pays attention to mining contextual information at the sentence level based on various types of syntactic and linguistic information encoded by the embedding module.</li>
</ul>
<h4 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h4><ul>
<li>RNNs are called recurrent as outputs in each time step depending on the previous computations.</li>
<li>Applied to deal with sequential information.</li>
<li>In particular, long short-term memory (LSTM), gated recurrent units (GRUs), variants of RNNs, are much better at capturing long-term dependencies than plain ones are and can alleviate gradient explosion and vanishing problems.</li>
<li>The preceding and following words have the same importance in understanding the given word, bidirectional RNNs have been widly used. </li>
</ul>
<p>The feature extraction process with bidirectional RNNs can be sorted into two types:<br><strong>word-level</strong><br>Feature extraction outputs for each embedding $x$ at time step $j$.<br><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/word-level-encoding.png" alt></p>
<p><strong>sentence-level</strong><br>Sentence-level encoding regards the question sentence as a whole.<br><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/sentence-level-encoding.png" alt></p>
<h4 id="Convolution-Neural-Networks"><a href="#Convolution-Neural-Networks" class="headerlink" title="Convolution Neural Networks"></a>Convolution Neural Networks</h4><p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/cnn-encoding.png" alt></p>
<ul>
<li>The convolution layer has two filter sizes $f_t \times d$ with $k$ output channels, where $d$ is the dimension of word embedding.</li>
<li>Each filter produces a feature map of shape $(|l| − t + 1) \times k$, where $l$ is the length of sentence.</li>
<li>One major shortcoming of CNNs is that they can extract only local information but are not capable of dealing with long sequence.</li>
</ul>
<h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/transformer-encoding.png" alt></p>
<ul>
<li>Mainly based on the attention mechanism and multi-head self-attention.</li>
<li>Add position encoding to make use of the order information.</li>
<li>In practice, models usually stack several blocks with multi-head self-attention and feed-forward network.</li>
</ul>
<p><strong>QANet</strong> is a representative MRC model that uses the transformer. The basic encoder block of QANet is a novel architecture, which combines the multi-head self-attention defined in the transformer with convolutions. </p>
<h3 id="Context-Question-Interaction"><a href="#Context-Question-Interaction" class="headerlink" title="Context-Question Interaction"></a>Context-Question Interaction</h3><blockquote>
<p>Extracting the correlation between the context and the question</p>
</blockquote>
<h4 id="Unidirectional-Attention"><a href="#Unidirectional-Attention" class="headerlink" title="Unidirectional Attention"></a>Unidirectional Attention</h4><p>Unidirectional attention flow is usually from query to context, highlighting the most relevant parts of the context according to the question.<br>The similarity of each context semantic embedding $P_i$ and the whole question sentence representations Q is calculated by $S_i = f(P_i, Q)$, where $f(\cdot)$ represents the function that can measure the similarity.<br>After being normalized by Softmax, the attention weight for each context word is obtained.  </p>
<p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/unidirectional_attention.png" alt></p>
<p>However, this method fails to pay attention to question words that are also pivotal for answer prediction. Hence, unidirectional attention flow is insufficient for extracting mutual information between the context and the query.</p>
<h4 id="Bidirectional-Attention"><a href="#Bidirectional-Attention" class="headerlink" title="Bidirectional Attention"></a>Bidirectional Attention</h4><p>Bidirectional attention flows, not only computes query-to-context attention but also the reverse, context-to-query attention.</p>
<p>The process of computing bidirectional attention:</p>
<ol>
<li>the pair-wise matching matrix $M(i, j)$ is obtained by computing the matching scores between each context semantic embedding $P_i$ and question semantic embedding $Q_j$ (word-level).   </li>
<li>Then the outputs of the column-wise SoftMax function can be regarded as query-to-context attention weight $\alpha$ while context-to-query attention $\beta$ is calculated by the row-wise SoftMax function</li>
</ol>
<p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/bidirectional_attention.png" alt></p>
<p>Bidirectional Attention based methods:  </p>
<ul>
<li>AoA Reader(Attention over Attention): compute the dot product between each context embedding and query embedding to obtain a similarity matching matrix $M$. And introducing attended attention, computed by the dot product of $\alpha$ and the average result of $\bata$, which is later used to predict the answer.</li>
<li>DCN(Dynamic Coattention Network)</li>
<li>Bi-DAF(Bidirectional Attention Flow)</li>
<li>DCN+: Using residual connections to merge coattention outputs to encode richer information for the input sequences.</li>
</ul>
<h4 id="One-Hop-Interaction"><a href="#One-Hop-Interaction" class="headerlink" title="One-Hop Interaction"></a>One-Hop Interaction</h4><blockquote>
<p>The interaction between the context and the question is computed only once.</p>
</blockquote>
<p>Although this method can do well in tackling simple cloze tests, when the question requires reasoning over multiple sentences in the context, it is hard for this one-hop interaction approach to predict the correct answer.       </p>
<h4 id="Multi-Hop-Interaction"><a href="#Multi-Hop-Interaction" class="headerlink" title="Multi-Hop Interaction"></a>Multi-Hop Interaction</h4><blockquote>
<p>It tries to mimic the rereading phenomenon of humans by computing the interaction between the context and the question more than once.        </p>
</blockquote>
<p>Mainly methods to perform multi-hop interaction:    </p>
<ol>
<li>Calculating the similarity between the context and the question based on previous attentive representations of context.      <ul>
<li>e.g.  Impatient Reader model: query-aware context representations are dynamically updated by this method as each query token is<br>read.</li>
</ul>
</li>
<li>Using external memory slots to store previous memories. <ul>
<li>After being given the context as input, the memory mechanism stores information of the context in memory slots and then updates them dynamically.  </li>
<li>End-to-end version of memory networks: memory storage is embedded with continuous representations and the process of reading and updating memories is modeled by neural networks.</li>
<li>MEMEN model: Stores question-aware context representations, context-aware question representations, and candidate answer representations in memory slots and updates them dynamically.</li>
</ul>
</li>
<li>Using hidden states to store previous interaction information.<ul>
<li>R-NET and iterative alternating reader (IA Reader) [14] also use RNNs to update query-aware context representations to perform<br>multi-hop interaction.</li>
</ul>
</li>
</ol>
<p><strong>Gate Machanism</strong>  </p>
<blockquote>
<p>Which can control the amount of mutual information between the context and the question, is a key component in multi-hop interaction.</p>
</blockquote>
<p>The gate mechanism, which is performed by a feed-forward network, is applied to determine the degree of matching between the context and the query. Or to filter out insignificant parts in the context and emphasize the ones most relevant to the question.   </p>
<h3 id="Answer-Prediction"><a href="#Answer-Prediction" class="headerlink" title="Answer Prediction"></a>Answer Prediction</h3><p>The implementation of answer prediction is highly task-specific.</p>
<h4 id="Word-Predictor"><a href="#Word-Predictor" class="headerlink" title="Word Predictor"></a>Word Predictor</h4><p>Cloze tests require filling in blanks with missing words or entities. </p>
<ul>
<li>Attentive Reader: The combination of the query-aware context and the question is reflected in the vocabulary space to<br>search for the correct answer word. But it cannot handle situation that answer is not in the context.</li>
</ul>
<h4 id="Option-Selector"><a href="#Option-Selector" class="headerlink" title="Option Selector"></a>Option Selector</h4><p>To tackle the multiple-choice task, the model should select the correct answer from candidate options. The common way is to measure the similarity between attentive context representations and candidate answer representations.</p>
<h4 id="Span-Extractor"><a href="#Span-Extractor" class="headerlink" title="Span Extractor"></a>Span Extractor</h4><p>The span extraction task can be regarded as an extension of cloze tests, which requires extracting a subsequence from the context rather than a single word.</p>
<h4 id="Answer-Generator"><a href="#Answer-Generator" class="headerlink" title="Answer Generator"></a>Answer Generator</h4><p>With the appearance of free answering tasks, answers are no longer limited to a subsequence of the original context; instead, they need to be synthesized from the context and the question.</p>
<h2 id="Additional-Tricks"><a href="#Additional-Tricks" class="headerlink" title="Additional Tricks"></a>Additional Tricks</h2><h3 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h3><p>In a word, reinforcement learning can be regarded as an improved approach in MRC systems that is capable of not only reducing the gap between optimization objectives and evaluation metrics but also determining whether to stop reasoning dynamically. With reinforcement learning, the model can be trained and refine better answers even if some states are discrete.</p>
<h3 id="Answer-Ranker"><a href="#Answer-Ranker" class="headerlink" title="Answer Ranker"></a>Answer Ranker</h3><p>The common process of ranker is that it extracts some candidate answers, and the one with the highest score is the correct answer.</p>
<h3 id="Sentence-Selector"><a href="#Sentence-Selector" class="headerlink" title="Sentence Selector"></a>Sentence Selector</h3><p>In practice, if the MRC model is given a long document, it takes a lot of times to understand the full context to answer questions. However, finding the sentences that are most relevant to the questions in advance is a possible way to accelerate the training process.</p>
<h1 id="Dataset-and-Evaluation-Metrics"><a href="#Dataset-and-Evaluation-Metrics" class="headerlink" title="Dataset and Evaluation Metrics"></a>Dataset and Evaluation Metrics</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>Highlighting:       </p>
<ol>
<li>How to construct large-scale datasets according to task requirements.</li>
<li>How to reduce lexical overlap between questions and context.</li>
</ol>
<h3 id="Cloze-Tests-Datasets"><a href="#Cloze-Tests-Datasets" class="headerlink" title="Cloze Tests Datasets"></a>Cloze Tests Datasets</h3><ul>
<li>CNN &amp; Daily Mail</li>
<li>The Children’s Book Test (CBT)</li>
<li>LAMBADA(Discourse aspects (LAMBADA) dataset)</li>
<li>Who-did-What: Each sample is formed from two independent articles; one serves as the context and questions are generated from<br>the other.</li>
<li>CLOTH: cloze test by teachers (CLOTH)</li>
<li>CliCR: A large-scale cloze-style dataset based on clinical case reports for healthcare and medicine</li>
</ul>
<h3 id="Multiple-Choice-Dataset"><a href="#Multiple-Choice-Dataset" class="headerlink" title="Multiple-Choice Dataset"></a>Multiple-Choice Dataset</h3><ul>
<li>MCTest: It consists of 500 fictional stories, and for each story there are four questions with four candidate answers.</li>
<li>RACE: As a multiple-choice task, RACE asks for more reasoning, because questions and answers are human-generated and simple methods based on information retrieval or word co-occurrence may not perform well.</li>
</ul>
<h3 id="Span-Extraction-Dataset"><a href="#Span-Extraction-Dataset" class="headerlink" title="Span Extraction Dataset"></a>Span Extraction Dataset</h3><ul>
<li>SQuAD: The Stanford Question-Answering Dataset (SQuAD).  Collecting 536 articles from Wikipedia, Rajpurkar et al, and ask crowd-workers to pose more than 100,000 questions and select a span of arbitrary length from the given article to answer the question.</li>
<li>NewsQA: Articles are collected from CNN. Some questions in NewsQA have no answer according to the given context.</li>
<li>TriviaQA: Gather question-answer pairs from trivia and quiz-league websites. Then they search for evidence to answer questions from webpages and Wikipedia. Finally, they build more than 650,00 question-answer-evidence triples for the MRC task.</li>
<li>DuoRC: Try to reduce lexical overlap between questions and contexts in DuoRC. Questions and answers in DuoRC are created from two different versions of documents.</li>
</ul>
<h3 id="Free-Answering-Datasets"><a href="#Free-Answering-Datasets" class="headerlink" title="Free Answering Datasets"></a>Free Answering Datasets</h3><ul>
<li>bAbI: A well-known synthetic MRC dataset. It consists of 20 tasks, generated with a simulation of a classic text adventure game. Each task is independent from the others and tests one aspect of text understanding.</li>
<li>MS MARCO: Can be viewed as another milestone of MRC after SQuAD. (1)Collected from real queries. (2)search with Bing search engine to serve as context. (3)label answers are generated by humans. (4)there are multiple answers to each question and sometimes they even conflict.</li>
<li>SearchQA: Like TriviaQA. The major difference between SearchQA and TriviaQA is that in TriviaQA there is one document with evidence for each question-answer pair, while in SearchQA each pair has 49.6 related snippets on average.</li>
<li>NarrativeQA: Generate question-answer pairs according to those summaries. What makes NarrativeQA special is that answering questions requires understanding the whole narrative.  </li>
<li>DuReader: A large-scale MRC dataset from real-world application. (1)Questions and documents are collected from Baidu. (2)It provides new question types such as yes/no and opinion.</li>
</ul>
<h2 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h2><h3 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h3><p>Given $m$ questions, correctly predicts answers for $n$ question, then accuracy=$\frac{n}{m}$</p>
<h3 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h3><p><img src="/2022/07/19/Machine-Reaeding-Comprehension-Survey/f1.png" alt></p>
<p>precision = $\frac{TP}{TP+FP}$<br>recall = $\frac{TP}{TP+FN}$<br>F! = $\frac{2 \times P \times R}{P + R}$            </p>
<h3 id="ROUGE-L"><a href="#ROUGE-L" class="headerlink" title="ROUGE-L"></a>ROUGE-L</h3><blockquote>
<p>Recall-Oriented Understudy for Gisting Evaluation, initially developed for automatic summarization.</p>
</blockquote>
<p>$R_{ls} = \frac{LCS(X, Y)}{m}$<br>$P_{ls} = \frac{LCS(X, Y)}{n}$<br>$F_{lcs} = \frac{(1+\beta)^2)R_{lcs}P_{lcs}}{R_{lcs} + \beta^2 P_{lcs}}$  </p>
<ul>
<li>$X$ is ground-truth answer with $m$ tokens;</li>
<li>$Y$ is model-generated answer with $n$ tokens;</li>
<li>$LCS(X, Y)$ denotes the length of the longest common subsequence of $X$ and $Y$;</li>
<li>$\beta$ is a parameter to control the importance of precision $P_{lcs}$ and recall $R_{lcs}$</li>
</ul>
<p>However, the length of candidate answers influences the value of ROUGE-L.</p>
<h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><blockquote>
<p>Bilingual Evaluation Understudy, is widely used to evaluate translation performance.</p>
</blockquote>
<p>BLEU score measures the similarity between predicted answers and ground truth:<br>$P_n(C, R) = \frac{\sum_i \sum_k min(h_k(c_i), max(h_k(r_i)))}{\sum_i \sum_k h_k(c_i)}$     </p>
<ul>
<li>$h_k(c_i)$ counts the number of $k$-th n-gram appearing in candidate answer $c_i$;    </li>
<li>$h_k(r_i)$ denotes the occurrence number of that n-gram in gold answer $r_i$. </li>
</ul>
<p>As the value of $P_n(C, R)$ is higher when the answer span is shorter. The penalty factor, BP, is introduced to alleviate that.<br>$$<br>BP = \left{\begin{matrix}<br>  1, &amp; l_c &gt; l_r \<br>  e^{1-\frac{l_r}{l_c}}, &amp; l_c \le l_r<br>\end{matrix}\right.<br>$$</p>
<p>Finally, the BLEU score is computed as follows:<br>$BLEU = BP \cdot exp(\sum_{n=1}^N w_n logP_n)$      </p>
<ul>
<li>$N$ means n-grams up to length $N$;   </li>
<li>$w_n$ equals $\frac{1}{N}$.</li>
</ul>
<p>BLUE score can not only evaluate the similarity between candidate answer and ground-truth answers but alos test the readibility of candidates.      </p>
<h1 id="New-Trends"><a href="#New-Trends" class="headerlink" title="New Trends"></a>New Trends</h1><h2 id="Knowledge-Based-Machine-Reading-Comprehension"><a href="#Knowledge-Based-Machine-Reading-Comprehension" class="headerlink" title="Knowledge-Based Machine Reading Comprehension"></a>Knowledge-Based Machine Reading Comprehension</h2><blockquote>
<p>Given the context $C$, question $Q$ and external knowledge $K$, the task requires predicting the correct answer $A$ by learning the function $F$ such that $A=F(C, Q, K)$     </p>
</blockquote>
<p><strong>The key challenges in KBMRC</strong></p>
<h3 id="Relevant-External-Knowledge-Retrieval"><a href="#Relevant-External-Knowledge-Retrieval" class="headerlink" title="Relevant External Knowledge Retrieval"></a>Relevant External Knowledge Retrieval</h3><p>There are various kinds of knowledge stored in knowledge bases, and entities may be misleading sometimes because of polysemy, e.g., “apple” can refer to a fruit or a corporation.</p>
<h3 id="External-Knowledge-Integration"><a href="#External-Knowledge-Integration" class="headerlink" title="External Knowledge Integration"></a>External Knowledge Integration</h3><p>Knowledge in an external knowledge base has its own unique structure. How to encode such knowledge and integrate it with representations of the context and questions remains an ongoing research challenge.        </p>
<h2 id="Machine-Reading-Comprehension-with-Unanswerable-Questions"><a href="#Machine-Reading-Comprehension-with-Unanswerable-Questions" class="headerlink" title="Machine Reading Comprehension with Unanswerable Questions"></a>Machine Reading Comprehension with Unanswerable Questions</h2><blockquote>
<p>Given the context $C$ and question $Q$, the machine first determines whether $Q$ can be answered or not based on the given context $C$. If the question is impossible to be answered, the model marks it as unanswerable and abstain from answering, otherwise predicts the correct answer $A$ by learning the function $F$ such that $A=F(C, Q)$     </p>
</blockquote>
<h3 id="Unanswerable-Questions"><a href="#Unanswerable-Questions" class="headerlink" title="Unanswerable Questions"></a>Unanswerable Questions</h3><p>There is a latent hypothesis behind MRC tasks that correct answers always exist in the given context. However, this does not conform with real-world application. A mature MRC system should distinguish those unanswerable questions.</p>
<p>SQuAD 2.0 is a representative MRC dataset with unanswerable questions.</p>
<h4 id="Unanswerable-Question-Detection"><a href="#Unanswerable-Question-Detection" class="headerlink" title="Unanswerable Question Detection"></a>Unanswerable Question Detection</h4><p>After comprehending the question and reasoning through the passage, the MRC models should judge which questions are impossible to answer based on the given context and mark them as unanswerable.</p>
<h4 id="Plausible-貌似真实的-Answer-Discrimination"><a href="#Plausible-貌似真实的-Answer-Discrimination" class="headerlink" title="Plausible(貌似真实的) Answer Discrimination"></a>Plausible(貌似真实的) Answer Discrimination</h4><p>The MRC model must verify the predicted answers and tell plausible answers from correct ones.</p>
<h2 id="Multi-Passage-Machine-Reading-Comprehension"><a href="#Multi-Passage-Machine-Reading-Comprehension" class="headerlink" title="Multi-Passage Machine Reading Comprehension"></a>Multi-Passage Machine Reading Comprehension</h2><blockquote>
<p>Given a collection of m documents $D = {D_1, D_2, \cdots, D_m}$ and the question $Q$, the multi-passage MRC task requires giving the correct answer $A$ to question $Q$ according to document $D$ by learning the function $F$ such that $A=F(D, Q)$    </p>
</blockquote>
<h3 id="Massive-Document-Corpus"><a href="#Massive-Document-Corpus" class="headerlink" title="Massive Document Corpus"></a>Massive Document Corpus</h3><p>Under this circumstance, whether a model can retrieve the most relevant documents from the corpus quickly and correctly decides the final performance of readin comprehension.</p>
<h3 id="Noisy-Document-Retrieval"><a href="#Noisy-Document-Retrieval" class="headerlink" title="Noisy Document Retrieval"></a>Noisy Document Retrieval</h3><p>Sometimes the model may retrieve a noisy document that contains the correct answer span, but it is not related to the question. This noise will mislead the understanding of the context.</p>
<h3 id="No-Answer"><a href="#No-Answer" class="headerlink" title="No Answer"></a>No Answer</h3><p>When the retrieval component does not perform well, there will be no answers in the document.</p>
<h3 id="Multiple-Answers"><a href="#Multiple-Answers" class="headerlink" title="Multiple Answers"></a>Multiple Answers</h3><p>In the open-domain setting, it is common to find multiple answers for a single question.</p>
<h3 id="Evidence-Aggregation"><a href="#Evidence-Aggregation" class="headerlink" title="Evidence Aggregation"></a>Evidence Aggregation</h3><p>In terms of some complicated questions, snippets of evidence can appear in different parts of one document or even in different documents.</p>
<h2 id="Conversational-Machine-Reading-Comprehension"><a href="#Conversational-Machine-Reading-Comprehension" class="headerlink" title="Conversational Machine Reading Comprehension"></a>Conversational Machine Reading Comprehension</h2><blockquote>
<p>Given the context $C$, the converssation history with previous questions and answers $H={A_1, A_1, \cdots, Q_{i-1}, A_{i-1}}$ and current question $Q$, the CMRC task is to predict the correct answer $A_i$ by learning the function $F$ that $A_i=F(C, H, Q_i)$</p>
</blockquote>
<p>MRC requires answering a question based on the understanding of a given passage, with questions usually isolated from each other. However, the most natural way that people acquire knowledge is via a series of interrelated question-and-answer processes.    </p>
<h3 id="Conversational-History"><a href="#Conversational-History" class="headerlink" title="Conversational History"></a>Conversational History</h3><p>A follow-up question may be closely related to prior questions and answers.</p>
<h3 id="Coreference-Resolution-指代消解"><a href="#Coreference-Resolution-指代消解" class="headerlink" title="Coreference Resolution(指代消解)"></a>Coreference Resolution(指代消解)</h3><p>Coreference can be sorted into two kinds, explicit and implicit.</p>
<ul>
<li>With explicit coreference, there are explicit markers, such as some personal pronouns.</li>
<li>By comparison, implicit coreference without explicit markers is much harder to figure out. Short questions with certain intentions that implicitly refer to previous content are a kind of implicit coreference.</li>
</ul>
<h1 id="Open-Issues"><a href="#Open-Issues" class="headerlink" title="Open Issues"></a>Open Issues</h1><ul>
<li>Limitation of Given Context</li>
<li>Robustness of MRC Systems</li>
<li>Incorporation of External Knowledge</li>
<li>Lack of Inference Ability</li>
<li>Diffificulty in Interpretation</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Paper/" rel="tag"># Paper</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/17/Word-Embedding/" rel="prev" title="Word Embedding">
      <i class="fa fa-chevron-left"></i> Word Embedding
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MDY4OC8yNzE3MQ"></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Llunch</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/next-boot.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":false},"rect":"opacity:0.7","log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
